#!/usr/bin/env python3
"""
Calculate Generation Diversity Matrices

è¨ˆç®—æŒ‡å®šä¸–ä»£çš„ PnL correlation matrix å’Œæ¨™æº–åŒ– TED distance matrixã€‚
æ”¯æ´æ¡æ¨£å’Œå¹³è¡ŒåŒ–è¨ˆç®—ã€‚
"""

import sys
import pickle
import json
import argparse
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Tuple
from deap import creator, base, gp
from joblib import Parallel, delayed
from tqdm import tqdm

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

from gp_quant.evolution.components.gp import operators
from gp_quant.evolution.components.backtesting import PortfolioBacktestingEngine
from gp_quant.data.loader import load_and_process_data, split_train_test_data
from gp_quant.similarity.tree_edit_distance import compute_ted


def setup_deap_creator():
    """è¨­ç½® DEAP creator"""
    if not hasattr(creator, "FitnessMax"):
        creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    if not hasattr(creator, "Individual"):
        creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessMax)


def load_generation_population(records_dir: Path, generation: int = None) -> Tuple[List, int]:
    """
    è¼‰å…¥æŒ‡å®šä¸–ä»£çš„æ—ç¾¤
    
    Args:
        records_dir: è¨˜éŒ„ç›®éŒ„è·¯å¾‘
        generation: ä¸–ä»£è™Ÿï¼ˆNone è¡¨ç¤ºæœ€æ–°ä¸€ä»£ï¼‰
        
    Returns:
        (population, generation_number)
    """
    populations_dir = records_dir / 'populations'
    
    if not populations_dir.exists():
        raise ValueError(f"Populations directory not found: {populations_dir}")
    
    # æ‰¾åˆ°æ‰€æœ‰ generation_XXX.pkl æ–‡ä»¶
    gen_files = sorted(populations_dir.glob('generation_*.pkl'))
    
    if len(gen_files) == 0:
        raise ValueError("No generation files found")
    
    # å¦‚æœæœªæŒ‡å®šä¸–ä»£ï¼Œä½¿ç”¨æœ€æ–°ä¸€ä»£
    if generation is None:
        gen_file = gen_files[-1]
        generation = int(gen_file.stem.split('_')[1])
    else:
        gen_file = populations_dir / f'generation_{generation:03d}.pkl'
        if not gen_file.exists():
            raise ValueError(f"Generation {generation} not found")
    
    print(f"ğŸ“‚ è¼‰å…¥ä¸–ä»£ {generation}: {gen_file.name}")
    
    with open(gen_file, 'rb') as f:
        population = pickle.load(f)
    
    print(f"   âœ… è¼‰å…¥ {len(population)} å€‹å€‹é«”")
    
    return population, generation


def sample_population(population: List, sample_size: int, strategy: str = 'stratified') -> List:
    """
    å¾æ—ç¾¤ä¸­æ¡æ¨£
    
    Args:
        population: å®Œæ•´æ—ç¾¤
        sample_size: æ¡æ¨£å¤§å°
        strategy: æ¡æ¨£ç­–ç•¥ ('stratified' æˆ– 'random')
        
    Returns:
        æ¡æ¨£å¾Œçš„æ—ç¾¤
    """
    n = len(population)
    
    if sample_size >= n:
        print(f"   â„¹ï¸  æ¡æ¨£å¤§å° ({sample_size}) >= æ—ç¾¤å¤§å° ({n})ï¼Œä½¿ç”¨å…¨éƒ¨å€‹é«”")
        return population
    
    print(f"   ğŸ² æ¡æ¨£ç­–ç•¥: {strategy}, å¾ {n} å€‹å€‹é«”ä¸­æ¡æ¨£ {sample_size} å€‹")
    
    if strategy == 'stratified':
        # æŒ‰ fitness æ’åºå¾Œå‡å‹»æ¡æ¨£
        sorted_pop = sorted(population, key=lambda ind: ind.fitness.values[0], reverse=True)
        indices = np.linspace(0, n - 1, sample_size, dtype=int)
        sampled = [sorted_pop[i] for i in indices]
        print(f"   âœ… åˆ†å±¤æ¡æ¨£å®Œæˆï¼ˆåŒ…å«é«˜ã€ä¸­ã€ä½ fitness å€‹é«”ï¼‰")
    else:
        # éš¨æ©Ÿæ¡æ¨£
        indices = np.random.choice(n, sample_size, replace=False)
        sampled = [population[i] for i in indices]
        print(f"   âœ… éš¨æ©Ÿæ¡æ¨£å®Œæˆ")
    
    return sampled


def calculate_pnl_for_individual(individual: Any, 
                                  engine: PortfolioBacktestingEngine) -> np.ndarray:
    """
    è¨ˆç®—å–®å€‹å€‹é«”çš„ PnL curve
    
    Args:
        individual: DEAP individual
        engine: å›æ¸¬å¼•æ“
        
    Returns:
        PnL curve as numpy array
    """
    try:
        pnl_curve = engine.get_pnl_curve(individual)
        return pnl_curve.values
    except Exception as e:
        # å¦‚æœè¨ˆç®—å¤±æ•—ï¼Œè¿”å›å…¨é›¶
        return np.zeros(len(engine.common_dates))


def calculate_pnl_correlation_matrix(population: List,
                                     train_data: Dict,
                                     config: Dict,
                                     n_jobs: int = 4) -> Tuple[np.ndarray, List[int]]:
    """
    è¨ˆç®— PnL correlation matrixï¼ˆå¹³è¡ŒåŒ–ï¼‰
    
    Args:
        population: æ—ç¾¤åˆ—è¡¨
        train_data: è¨“ç·´æ•¸æ“š
        config: é…ç½®å­—å…¸
        n_jobs: å¹³è¡Œè™•ç†å™¨æ•¸é‡
        
    Returns:
        (Correlation matrix (n x n), list of invalid indices)
    """
    n = len(population)
    print(f"\nğŸ’° è¨ˆç®— PnL Correlation Matrix ({n} x {n})...")
    
    # æå–è¨“ç·´æ•¸æ“š
    train_data_dict = {ticker: info['data'] for ticker, info in train_data.items()}
    
    # å‰µå»ºå›æ¸¬å¼•æ“
    engine = PortfolioBacktestingEngine(
        data=train_data_dict,
        backtest_start=config['data']['train_backtest_start'],
        backtest_end=config['data']['train_backtest_end'],
        initial_capital=100000.0
    )
    
    # å¹³è¡Œè¨ˆç®—æ‰€æœ‰å€‹é«”çš„ PnL curves
    print(f"   ğŸ”„ å¹³è¡Œè¨ˆç®— PnL curves (n_jobs={n_jobs})...")
    pnl_curves = Parallel(n_jobs=n_jobs)(
        delayed(calculate_pnl_for_individual)(ind, engine)
        for ind in tqdm(population, desc="   è¨ˆç®— PnL", ncols=80)
    )
    
    # è½‰æ›ç‚ºçŸ©é™£
    pnl_matrix = np.array(pnl_curves)
    
    # æª¢æŸ¥æœ‰æ•ˆæ€§ï¼ˆè­˜åˆ¥å…¨é›¶çš„ PnL curvesï¼‰
    valid_mask = ~np.all(pnl_matrix == 0, axis=1)
    invalid_indices = np.where(~valid_mask)[0].tolist()
    valid_count = np.sum(valid_mask)
    
    print(f"   âœ… æœ‰æ•ˆ PnL curves: {valid_count}/{n}")
    if len(invalid_indices) > 0:
        print(f"   âš ï¸  ç„¡æ•ˆå€‹é«”ï¼ˆå…¨é›¶ PnLï¼‰: {invalid_indices}")
        print(f"      é€™äº›å€‹é«”çš„ fitness: {[population[i].fitness.values[0] for i in invalid_indices]}")
    
    # è¨ˆç®—ç›¸é—œæ€§çŸ©é™£
    print(f"   ğŸ“Š è¨ˆç®—ç›¸é—œæ€§çŸ©é™£...")
    corr_matrix = np.corrcoef(pnl_matrix)
    
    # è™•ç† NaNï¼ˆç”±æ–¼å…¨é›¶ PnL curve å°è‡´çš„æ¨™æº–å·®ç‚º 0ï¼‰
    # å°‡ NaN æ›¿æ›ç‚º 0ï¼ˆè¡¨ç¤ºç„¡ç›¸é—œæ€§ï¼‰
    corr_matrix = np.nan_to_num(corr_matrix, nan=0.0)
    
    # å°æ–¼ç„¡æ•ˆå€‹é«”ï¼Œæ˜ç¢ºæ¨™è¨˜
    # å°‡å…¶èˆ‡å…¶ä»–å€‹é«”çš„ç›¸é—œæ€§è¨­ç‚º 0ï¼ˆè¡¨ç¤ºç„¡æ•ˆï¼‰
    for idx in invalid_indices:
        corr_matrix[idx, :] = 0.0
        corr_matrix[:, idx] = 0.0
        corr_matrix[idx, idx] = 1.0  # å°è§’ç·šä¿æŒç‚º 1
    
    # ç¢ºä¿å°è§’ç·šç‚º 1ï¼ˆå°æ–¼æ‰€æœ‰å€‹é«”ï¼‰
    np.fill_diagonal(corr_matrix, 1.0)
    
    # çµ±è¨ˆä¿¡æ¯ï¼ˆåªè¨ˆç®—æœ‰æ•ˆå€‹é«”ä¹‹é–“çš„ç›¸é—œæ€§ï¼‰
    valid_pairs = []
    for i in range(n):
        for j in range(i + 1, n):
            if i not in invalid_indices and j not in invalid_indices:
                valid_pairs.append(corr_matrix[i, j])
    
    if len(valid_pairs) > 0:
        mean_corr = np.mean(valid_pairs)
        std_corr = np.std(valid_pairs)
        print(f"   âœ… å¹³å‡ç›¸é—œæ€§ï¼ˆæœ‰æ•ˆå€‹é«”ï¼‰: {mean_corr:.4f} Â± {std_corr:.4f}")
        print(f"   âœ… ç›¸é—œæ€§ç¯„åœ: [{np.min(valid_pairs):.4f}, {np.max(valid_pairs):.4f}]")
    else:
        print(f"   âš ï¸  æ²’æœ‰è¶³å¤ çš„æœ‰æ•ˆå€‹é«”ä¾†è¨ˆç®—ç›¸é—œæ€§")
    
    return corr_matrix, invalid_indices


def calculate_ted_for_pair(i: int, j: int, ind_i: Any, ind_j: Any) -> Tuple[int, int, float]:
    """
    è¨ˆç®—ä¸€å°å€‹é«”çš„æ¨™æº–åŒ– TED
    
    Args:
        i, j: å€‹é«”ç´¢å¼•
        ind_i, ind_j: å€‹é«”
        
    Returns:
        (i, j, normalized_ted)
    """
    try:
        ted = compute_ted(ind_i, ind_j)
        max_size = max(len(ind_i), len(ind_j))
        norm_ted = ted / max_size if max_size > 0 else 0.0
        return i, j, norm_ted
    except Exception as e:
        # å¦‚æœè¨ˆç®—å¤±æ•—ï¼Œè¿”å›æœ€å¤§è·é›¢
        return i, j, 1.0


def calculate_ted_distance_matrix(population: List, n_jobs: int = 4) -> np.ndarray:
    """
    è¨ˆç®—æ¨™æº–åŒ– TED distance matrixï¼ˆå¹³è¡ŒåŒ–ï¼‰
    
    Args:
        population: æ—ç¾¤åˆ—è¡¨
        n_jobs: å¹³è¡Œè™•ç†å™¨æ•¸é‡
        
    Returns:
        Normalized TED distance matrix (n x n)
    """
    n = len(population)
    print(f"\nğŸŒ³ è¨ˆç®—æ¨™æº–åŒ– TED Distance Matrix ({n} x {n})...")
    
    # åˆå§‹åŒ–çŸ©é™£
    ted_matrix = np.zeros((n, n))
    
    # ç”Ÿæˆæ‰€æœ‰éœ€è¦è¨ˆç®—çš„é…å°ï¼ˆä¸Šä¸‰è§’ï¼‰
    pairs = [(i, j, population[i], population[j]) 
             for i in range(n) for j in range(i + 1, n)]
    
    total_pairs = len(pairs)
    print(f"   ğŸ”„ å¹³è¡Œè¨ˆç®— {total_pairs} å° TED (n_jobs={n_jobs})...")
    
    # å¹³è¡Œè¨ˆç®—
    results = Parallel(n_jobs=n_jobs)(
        delayed(calculate_ted_for_pair)(i, j, ind_i, ind_j)
        for i, j, ind_i, ind_j in tqdm(pairs, desc="   è¨ˆç®— TED", ncols=80)
    )
    
    # å¡«å……çŸ©é™£ï¼ˆå°ç¨±ï¼‰
    for i, j, ted in results:
        ted_matrix[i, j] = ted
        ted_matrix[j, i] = ted
    
    # å°è§’ç·šç‚º 0
    np.fill_diagonal(ted_matrix, 0.0)
    
    # çµ±è¨ˆä¿¡æ¯
    upper_tri = np.triu_indices(n, k=1)
    mean_ted = np.mean(ted_matrix[upper_tri])
    std_ted = np.std(ted_matrix[upper_tri])
    
    print(f"   âœ… å¹³å‡ TED è·é›¢: {mean_ted:.4f} Â± {std_ted:.4f}")
    print(f"   âœ… TED ç¯„åœ: [{np.min(ted_matrix[upper_tri]):.4f}, {np.max(ted_matrix[upper_tri]):.4f}]")
    
    return ted_matrix


def save_matrix_to_csv(matrix: np.ndarray, output_path: Path, generation: int, matrix_type: str):
    """
    ä¿å­˜çŸ©é™£åˆ° CSV
    
    Args:
        matrix: çŸ©é™£
        output_path: è¼¸å‡ºè·¯å¾‘
        generation: ä¸–ä»£è™Ÿ
        matrix_type: çŸ©é™£é¡å‹ï¼ˆ'pnl_corr' æˆ– 'ted_dist'ï¼‰
    """
    df = pd.DataFrame(matrix)
    df.to_csv(output_path, index=False, header=False)
    print(f"   ğŸ’¾ {matrix_type} çŸ©é™£å·²ä¿å­˜: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="è¨ˆç®—ä¸–ä»£å¤šæ¨£æ€§çŸ©é™£ï¼ˆPnL correlation å’Œ TED distanceï¼‰"
    )
    parser.add_argument(
        '--records',
        type=str,
        required=True,
        help='å¯¦é©—è¨˜éŒ„ç›®éŒ„è·¯å¾‘'
    )
    parser.add_argument(
        '--config',
        type=str,
        required=True,
        help='é…ç½®æ–‡ä»¶è·¯å¾‘'
    )
    parser.add_argument(
        '--generation',
        type=int,
        default=None,
        help='ä¸–ä»£è™Ÿï¼ˆé»˜èªç‚ºæœ€æ–°ä¸€ä»£ï¼‰'
    )
    parser.add_argument(
        '--sample-size',
        type=int,
        default=None,
        help='æ¡æ¨£å¤§å°ï¼ˆé»˜èªä½¿ç”¨å…¨éƒ¨å€‹é«”ï¼‰'
    )
    parser.add_argument(
        '--sample-strategy',
        type=str,
        default='stratified',
        choices=['stratified', 'random'],
        help='æ¡æ¨£ç­–ç•¥ï¼ˆé»˜èªï¼šstratifiedï¼‰'
    )
    parser.add_argument(
        '--n-jobs',
        type=int,
        default=4,
        help='å¹³è¡Œè™•ç†å™¨æ•¸é‡ï¼ˆé»˜èªï¼š4ï¼‰'
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        default=None,
        help='è¼¸å‡ºç›®éŒ„ï¼ˆé»˜èªä¿å­˜åœ¨è¨˜éŒ„ç›®éŒ„ä¸­ï¼‰'
    )
    
    args = parser.parse_args()
    
    records_dir = Path(args.records)
    config_file = Path(args.config)
    
    if not records_dir.exists():
        print(f"âŒ è¨˜éŒ„ç›®éŒ„ä¸å­˜åœ¨: {records_dir}")
        return
    
    if not config_file.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return
    
    print("=" * 80)
    print("ğŸ¯ Generation Diversity Matrices Calculation")
    print("=" * 80)
    print(f"Records directory: {records_dir}")
    print(f"Config file: {config_file}")
    print(f"Sample size: {args.sample_size if args.sample_size else 'All'}")
    print(f"N jobs: {args.n_jobs}\n")
    
    # 1. è¨­ç½® DEAP
    setup_deap_creator()
    
    # 2. è¼‰å…¥é…ç½®
    print("ğŸ“‹ è¼‰å…¥é…ç½®...")
    with open(config_file, 'r') as f:
        config = json.load(f)
    
    # 3. è¼‰å…¥ä¸–ä»£æ—ç¾¤
    print("\nğŸ“¦ è¼‰å…¥ä¸–ä»£æ—ç¾¤...")
    population, generation = load_generation_population(records_dir, args.generation)
    
    # 4. æ¡æ¨£ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if args.sample_size:
        population = sample_population(population, args.sample_size, args.sample_strategy)
    
    # 5. è¼‰å…¥æ•¸æ“š
    print("\nğŸ“Š è¼‰å…¥æ•¸æ“š...")
    import os
    tickers_dir = config['data']['tickers_dir']
    ticker_files = [f for f in os.listdir(tickers_dir) if f.endswith('.csv')]
    tickers = [f.replace('.csv', '') for f in ticker_files]
    print(f"   ç™¼ç¾ {len(tickers)} å€‹ ticker")
    
    data = load_and_process_data(tickers_dir, tickers)
    train_data, test_data = split_train_test_data(
        data,
        train_data_start=config['data']['train_data_start'],
        train_backtest_start=config['data']['train_backtest_start'],
        train_backtest_end=config['data']['train_backtest_end'],
        test_data_start=config['data']['test_data_start'],
        test_backtest_start=config['data']['test_backtest_start'],
        test_backtest_end=config['data']['test_backtest_end']
    )
    print(f"âœ… è¼‰å…¥ {len(train_data)} å€‹è‚¡ç¥¨çš„æ•¸æ“š")
    
    # 6. è¨ˆç®— PnL correlation matrix
    pnl_corr_matrix, invalid_indices = calculate_pnl_correlation_matrix(
        population, train_data, config, args.n_jobs
    )
    
    # 7. è¨ˆç®— TED distance matrix
    ted_dist_matrix = calculate_ted_distance_matrix(population, args.n_jobs)
    
    # 8. ä¿å­˜çŸ©é™£
    print("\nğŸ’¾ ä¿å­˜çŸ©é™£...")
    
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        output_dir = records_dir
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    pnl_corr_path = output_dir / f'pnl_correlation_matrix_gen{generation:03d}.csv'
    ted_dist_path = output_dir / f'ted_distance_matrix_normalized_gen{generation:03d}.csv'
    
    save_matrix_to_csv(pnl_corr_matrix, pnl_corr_path, generation, 'PnL Correlation')
    save_matrix_to_csv(ted_dist_matrix, ted_dist_path, generation, 'TED Distance')
    
    # 9. è¼¸å‡ºæ‘˜è¦
    print("\n" + "=" * 80)
    print("âœ… å®Œæˆ!")
    print("=" * 80)
    print(f"ä¸–ä»£: {generation}")
    print(f"å€‹é«”æ•¸é‡: {len(population)}")
    print(f"PnL å¹³å‡ç›¸é—œæ€§: {np.mean(pnl_corr_matrix[np.triu_indices(len(population), k=1)]):.4f}")
    print(f"TED å¹³å‡è·é›¢: {np.mean(ted_dist_matrix[np.triu_indices(len(population), k=1)]):.4f}")
    print(f"\nè¼¸å‡ºæ–‡ä»¶:")
    print(f"  - {pnl_corr_path}")
    print(f"  - {ted_dist_path}")
    print("=" * 80)


if __name__ == "__main__":
    main()
