"""
Run comprehensive experiments for all tickers
Each ticker will be tested 10 times with both short and long training periods
Supports parallel execution using multiprocessing
"""
import subprocess
import json
import re
from datetime import datetime
import pandas as pd
import os
from concurrent.futures import ProcessPoolExecutor, as_completed
from functools import partial

# modify_main_py() function removed - now using command-line arguments instead

def extract_results(output):
    """Extract key results from output"""
    results = {
        'train_gp_return': None,
        'train_bh_return': None,
        'train_excess_return': None,
        'test_gp_return': None,
        'test_bh_return': None,
        'test_excess_return': None,
        'best_fitness': None
    }
    
    # Extract GP returns
    gp_matches = re.findall(r'Total GP Return: \$([0-9,.-]+)', output)
    if len(gp_matches) >= 1:
        results['train_gp_return'] = float(gp_matches[0].replace(',', ''))
    if len(gp_matches) >= 2:
        results['test_gp_return'] = float(gp_matches[1].replace(',', ''))
    
    # Extract B&H returns
    bh_matches = re.findall(r'Total Buy-and-Hold Return: \$([0-9,.-]+)', output)
    if len(bh_matches) >= 1:
        results['train_bh_return'] = float(bh_matches[0].replace(',', ''))
    if len(bh_matches) >= 2:
        results['test_bh_return'] = float(bh_matches[1].replace(',', ''))
    
    # Extract excess returns
    excess_matches = re.findall(r'Total Excess Return: \$([0-9,.-]+)', output)
    if len(excess_matches) >= 1:
        results['train_excess_return'] = float(excess_matches[0].replace(',', ''))
    if len(excess_matches) >= 2:
        results['test_excess_return'] = float(excess_matches[1].replace(',', ''))
    
    # Extract best fitness
    fitness_match = re.search(r'Best Individual Fitness \(Total Excess Return\): \$([0-9,.-]+)', output)
    if fitness_match:
        results['best_fitness'] = float(fitness_match.group(1).replace(',', ''))
    
    return results

def run_single_experiment(ticker, period_name, 
                         train_data_start, train_backtest_start, train_backtest_end,
                         test_data_start, test_backtest_start, test_backtest_end,
                         run_number):
    """Run a single experiment (parallel-safe)"""
    # Reduced output for parallel execution
    print(f"ğŸ”¬ é–‹å§‹: {ticker} | {period_name} | Run {run_number}")
    
    # Create directory for this ticker if it doesn't exist
    ticker_dir = f"experiments_results/{ticker.replace('.', '_')}"
    os.makedirs(ticker_dir, exist_ok=True)
    
    # Run the experiment with date parameters
    start_time = datetime.now()
    
    result = subprocess.run([
        'python', 'main.py',
        '--tickers', ticker,
        '--mode', 'portfolio',
        '--generations', '50',
        '--population', '500',
        '--train_data_start', train_data_start,
        '--train_backtest_start', train_backtest_start,
        '--train_backtest_end', train_backtest_end,
        '--test_data_start', test_data_start,
        '--test_backtest_start', test_backtest_start,
        '--test_backtest_end', test_backtest_end
    ], capture_output=True, text=True)
    
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    # Extract results
    results = extract_results(result.stdout)
    results['duration'] = duration
    results['ticker'] = ticker
    results['period'] = period_name
    results['run_number'] = run_number
    results['timestamp'] = datetime.now().isoformat()
    
    # Save trade files to ticker-specific directory
    period_short = 'short' if period_name == 'çŸ­è¨“ç·´æœŸ' else 'long'
    
    # Move/copy trade CSV files
    train_trades = f"portfolio_train_{ticker}_trades.csv"
    test_trades = f"portfolio_test_{ticker}_trades.csv"
    
    if os.path.exists(train_trades):
        new_train_name = f"{ticker_dir}/{period_short}_run{run_number:02d}_train_trades.csv"
        os.rename(train_trades, new_train_name)
        results['train_trades_file'] = new_train_name
    
    if os.path.exists(test_trades):
        new_test_name = f"{ticker_dir}/{period_short}_run{run_number:02d}_test_trades.csv"
        os.rename(test_trades, new_test_name)
        results['test_trades_file'] = new_test_name
    
    # Move individual_records directory if it exists
    # Look for temporary individual_records directories (created with unique names)
    import glob
    individual_records_pattern = f"{ticker_dir}/individual_records_tmp_*"
    individual_records_dirs = glob.glob(individual_records_pattern)
    
    if individual_records_dirs:
        # Should only be one, but take the most recent if multiple
        individual_records_src = sorted(individual_records_dirs)[-1]
        individual_records_dst = f"{ticker_dir}/individual_records_{period_short}_run{run_number:02d}"
        
        if os.path.exists(individual_records_dst):
            import shutil
            shutil.rmtree(individual_records_dst)
        
        os.rename(individual_records_src, individual_records_dst)
        results['individual_records_dir'] = individual_records_dst
        
        # Calculate storage size
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(individual_records_dst):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                if os.path.exists(filepath):
                    total_size += os.path.getsize(filepath)
        results['individual_records_size_bytes'] = total_size
    
    # Save individual result JSON
    result_json_file = f"{ticker_dir}/{period_short}_run{run_number:02d}_result.json"
    with open(result_json_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    # Save full output log
    log_file = f"{ticker_dir}/{period_short}_run{run_number:02d}_output.log"
    with open(log_file, 'w') as f:
        f.write(result.stdout)
    
    # Print summary (compact for parallel execution)
    if results['test_excess_return'] is not None:
        status = "âœ…" if results['test_excess_return'] > 0 else "âŒ"
        print(f"âœ“ å®Œæˆ: {ticker} | {period_name} | Run {run_number} | "
              f"è¶…é¡: ${results['test_excess_return']:,.0f} {status} | {duration:.1f}s")
    
    return results

def run_all_experiments(max_workers=8):
    """
    Run all experiments for all tickers with parallel execution
    
    Args:
        max_workers: Maximum number of parallel workers (default: 8)
    """
    
    # Configuration
    tickers = ['ABX.TO', 'BBD-B.TO', 'RY.TO', 'TRP.TO']
    n_runs = 10
    
    experiments = [
        {
            'name': 'çŸ­è¨“ç·´æœŸ',
            'train_data_start': '1997-06-25',
            'train_backtest_start': '1998-06-22',
            'train_backtest_end': '1999-06-25',
            'test_data_start': '1998-07-07',
            'test_backtest_start': '1999-06-28',
            'test_backtest_end': '2000-06-30'
        },
        {
            'name': 'é•·è¨“ç·´æœŸ',
            'train_data_start': '1992-06-30',
            'train_backtest_start': '1993-07-02',
            'train_backtest_end': '1999-06-25',
            'test_data_start': '1998-07-07',
            'test_backtest_start': '1999-06-28',
            'test_backtest_end': '2000-06-30'
        }
    ]
    
    # Build list of all experiment tasks
    tasks = []
    for ticker in tickers:
        for exp in experiments:
            for run in range(1, n_runs + 1):
                tasks.append({
                    'ticker': ticker,
                    'period_name': exp['name'],
                    'train_data_start': exp['train_data_start'],
                    'train_backtest_start': exp['train_backtest_start'],
                    'train_backtest_end': exp['train_backtest_end'],
                    'test_data_start': exp['test_data_start'],
                    'test_backtest_start': exp['test_backtest_start'],
                    'test_backtest_end': exp['test_backtest_end'],
                    'run_number': run
                })
    
    total_experiments = len(tasks)
    all_results = []
    
    print("\n" + "ğŸš€"*50)
    print(f"é–‹å§‹å¤§è¦æ¨¡å¯¦é©—ï¼ˆä¸¦è¡ŒåŸ·è¡Œï¼‰")
    print(f"è‚¡ç¥¨æ•¸é‡: {len(tickers)}")
    print(f"è¨“ç·´æœŸé¡å‹: {len(experiments)}")
    print(f"æ¯å€‹é…ç½®é‹è¡Œæ¬¡æ•¸: {n_runs}")
    print(f"ç¸½å¯¦é©—æ•¸: {total_experiments}")
    print(f"ä¸¦è¡Œå·¥ä½œæ•¸: {max_workers}")
    print("ğŸš€"*50 + "\n")
    
    start_time_all = datetime.now()
    
    # Execute experiments in parallel
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        future_to_task = {
            executor.submit(
                run_single_experiment,
                ticker=task['ticker'],
                period_name=task['period_name'],
                train_data_start=task['train_data_start'],
                train_backtest_start=task['train_backtest_start'],
                train_backtest_end=task['train_backtest_end'],
                test_data_start=task['test_data_start'],
                test_backtest_start=task['test_backtest_start'],
                test_backtest_end=task['test_backtest_end'],
                run_number=task['run_number']
            ): task for task in tasks
        }
        
        # Process completed tasks as they finish
        completed = 0
        for future in as_completed(future_to_task):
            task = future_to_task[future]
            try:
                result = future.result()
                all_results.append(result)
                completed += 1
                
                # Progress update
                progress = (completed / total_experiments) * 100
                print(f"\nğŸ“Š ç¸½é€²åº¦: {completed}/{total_experiments} ({progress:.1f}%) | "
                      f"å‰›å®Œæˆ: {task['ticker']} {task['period_name']} Run {task['run_number']}")
                
            except Exception as e:
                print(f"âŒ éŒ¯èª¤ ({task['ticker']} {task['period_name']} Run {task['run_number']}): {e}")
                continue
    
    end_time_all = datetime.now()
    total_duration = (end_time_all - start_time_all).total_seconds()
    
    # Save all results
    results_df = pd.DataFrame(all_results)
    results_df.to_csv('all_experiments_results.csv', index=False)
    
    with open('all_experiments_results.json', 'w') as f:
        json.dump(all_results, f, indent=2)
    
    # Generate summary statistics
    generate_summary(results_df, total_duration)
    
    return results_df

def generate_summary(df, total_duration):
    """Generate summary statistics"""
    print("\n" + "="*100)
    print("ğŸ“Š å¯¦é©—ç¸½çµ")
    print("="*100)
    
    print(f"\nç¸½åŸ·è¡Œæ™‚é–“: {total_duration/60:.2f} åˆ†é˜ ({total_duration:.2f} ç§’)")
    print(f"ç¸½å¯¦é©—æ•¸: {len(df)}")
    
    # Summary by ticker and period
    summary = df.groupby(['ticker', 'period']).agg({
        'test_excess_return': ['mean', 'std', 'min', 'max'],
        'train_excess_return': ['mean', 'std'],
        'duration': 'mean'
    }).round(2)
    
    print("\n" + "="*100)
    print("å„è‚¡ç¥¨å„è¨“ç·´æœŸçš„çµ±è¨ˆæ‘˜è¦ (10æ¬¡é‹è¡Œ)")
    print("="*100)
    print(summary)
    
    # Win rate (beating buy-and-hold)
    print("\n" + "="*100)
    print("æ¨£æœ¬å¤–å‹ç‡ (è¶…è¶Š Buy-and-Hold çš„æ¯”ä¾‹)")
    print("="*100)
    
    for ticker in df['ticker'].unique():
        print(f"\n{ticker}:")
        for period in df['period'].unique():
            subset = df[(df['ticker'] == ticker) & (df['period'] == period)]
            wins = (subset['test_excess_return'] > 0).sum()
            total = len(subset)
            win_rate = (wins / total) * 100
            
            avg_excess = subset['test_excess_return'].mean()
            status = "âœ…" if win_rate > 50 else "âŒ"
            
            print(f"  {period}: {wins}/{total} ({win_rate:.0f}%) {status} | å¹³å‡è¶…é¡: ${avg_excess:,.2f}")
    
    # Best and worst performers
    print("\n" + "="*100)
    print("æœ€ä½³èˆ‡æœ€å·®è¡¨ç¾")
    print("="*100)
    
    best_idx = df['test_excess_return'].idxmax()
    worst_idx = df['test_excess_return'].idxmin()
    
    best = df.loc[best_idx]
    worst = df.loc[worst_idx]
    
    print(f"\næœ€ä½³è¡¨ç¾:")
    print(f"  è‚¡ç¥¨: {best['ticker']}")
    print(f"  è¨“ç·´æœŸ: {best['period']}")
    print(f"  ç¬¬ {best['run_number']} æ¬¡é‹è¡Œ")
    print(f"  æ¨£æœ¬å¤–è¶…é¡å ±é…¬: ${best['test_excess_return']:,.2f}")
    
    print(f"\næœ€å·®è¡¨ç¾:")
    print(f"  è‚¡ç¥¨: {worst['ticker']}")
    print(f"  è¨“ç·´æœŸ: {worst['period']}")
    print(f"  ç¬¬ {worst['run_number']} æ¬¡é‹è¡Œ")
    print(f"  æ¨£æœ¬å¤–è¶…é¡å ±é…¬: ${worst['test_excess_return']:,.2f}")
    
    # Overall conclusion
    print("\n" + "="*100)
    print("ğŸ¯ ç¸½é«”çµè«–")
    print("="*100)
    
    short_period = df[df['period'] == 'çŸ­è¨“ç·´æœŸ']
    long_period = df[df['period'] == 'é•·è¨“ç·´æœŸ']
    
    short_win_rate = (short_period['test_excess_return'] > 0).sum() / len(short_period) * 100
    long_win_rate = (long_period['test_excess_return'] > 0).sum() / len(long_period) * 100
    
    print(f"\nçŸ­è¨“ç·´æœŸç¸½é«”å‹ç‡: {short_win_rate:.1f}%")
    print(f"é•·è¨“ç·´æœŸç¸½é«”å‹ç‡: {long_win_rate:.1f}%")
    
    if long_win_rate > short_win_rate:
        print(f"\nâœ… é•·è¨“ç·´æœŸæ˜é¡¯å„ªæ–¼çŸ­è¨“ç·´æœŸ (å‹ç‡é«˜ {long_win_rate - short_win_rate:.1f}%)")
    else:
        print(f"\nâš ï¸ çŸ­è¨“ç·´æœŸè¡¨ç¾å„ªæ–¼é•·è¨“ç·´æœŸ (å‹ç‡é«˜ {short_win_rate - long_win_rate:.1f}%)")
    
    # Individual records storage statistics
    if 'individual_records_size_bytes' in df.columns:
        total_storage = df['individual_records_size_bytes'].sum()
        avg_storage = df['individual_records_size_bytes'].mean()
        
        def format_bytes(bytes_size):
            for unit in ['B', 'KB', 'MB', 'GB']:
                if bytes_size < 1024.0:
                    return f"{bytes_size:.2f} {unit}"
                bytes_size /= 1024.0
            return f"{bytes_size:.2f} TB"
        
        print("\n" + "="*100)
        print("ğŸ’¾ Individual Records å„²å­˜çµ±è¨ˆ")
        print("="*100)
        print(f"ç¸½å„²å­˜ç©ºé–“: {format_bytes(total_storage)}")
        print(f"å¹³å‡æ¯æ¬¡é‹è¡Œ: {format_bytes(avg_storage)}")
        print(f"å¯¦é©—ç¸½æ•¸: {len(df)}")
    
    print("\nâœ… æ‰€æœ‰çµæœå·²å„²å­˜è‡³:")
    print("   - all_experiments_results.csv (åŒ¯ç¸½è¡¨æ ¼)")
    print("   - all_experiments_results.json (åŒ¯ç¸½JSON)")
    print("\nğŸ“ å„è‚¡ç¥¨è©³ç´°æ–‡ä»¶çµæ§‹:")
    print("   experiments_results/")
    for ticker in df['ticker'].unique():
        ticker_clean = ticker.replace('.', '_')
        print(f"   â”œâ”€â”€ {ticker_clean}/")
        print(f"   â”‚   â”œâ”€â”€ short_run01_train_trades.csv")
        print(f"   â”‚   â”œâ”€â”€ short_run01_test_trades.csv")
        print(f"   â”‚   â”œâ”€â”€ short_run01_result.json")
        print(f"   â”‚   â”œâ”€â”€ short_run01_output.log")
        print(f"   â”‚   â”œâ”€â”€ individual_records_short_run01/ (æ—ç¾¤å¿«ç…§)")
        print(f"   â”‚   â”œâ”€â”€ ... (run02 åˆ° run10)")
        print(f"   â”‚   â”œâ”€â”€ long_run01_train_trades.csv")
        print(f"   â”‚   â”œâ”€â”€ long_run01_test_trades.csv")
        print(f"   â”‚   â”œâ”€â”€ long_run01_result.json")
        print(f"   â”‚   â”œâ”€â”€ long_run01_output.log")
        print(f"   â”‚   â”œâ”€â”€ individual_records_long_run01/ (æ—ç¾¤å¿«ç…§)")
        print(f"   â”‚   â””â”€â”€ ... (run02 åˆ° run10)")
    print("="*100 + "\n")

if __name__ == "__main__":
    results_df = run_all_experiments()
    
    print("\n" + "ğŸ‰"*50)
    print("æ‰€æœ‰å¯¦é©—å®Œæˆï¼")
    print("ğŸ‰"*50 + "\n")
