"""
Phase 1: Portfolio-Based GP Evolution Experiment (with Norm Operator)

å¤šè‚¡ç¥¨çµ„åˆçš„ GP æ¼”åŒ–å¯¦é©—
- ä½¿ç”¨ PortfolioBacktestingEngine åŒæ™‚è©•ä¼°å¤šå€‹è‚¡ç¥¨
- åŒ…å«æ–°å¯¦ä½œçš„ Norm operator
- å„²å­˜æ¯å€‹ generation çš„æ—ç¾¤å¿«ç…§
- 5000 å€‹é«”ï¼Œ50 ä»£æ¼”åŒ–ï¼ˆå¤§è¦æ¨¡å¯¦é©—ï¼‰
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime
from deap import creator, base, gp, tools
import random
import json
import os
import dill

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from gp_quant.backtesting.portfolio_engine import PortfolioBacktestingEngine
from gp_quant.gp.operators import pset
from gp_quant.evolution.early_stopping import EarlyStopping
from gp_quant.evolution.engine import run_evolution
from gp_quant.similarity import SimilarityMatrix, ParallelSimilarityMatrix
from gp_quant.niching import NichingClusterer, CrossNicheSelector, create_k_selector


def create_generation_callback(CONFIG, early_stopping, niching_selector, k_selector, 
                               generations_dir, evolution_log, niching_log):
    """
    å‰µå»º generation callback å‡½æ•¸ä¾†è™•ç†ï¼š
    1. Niching ç­–ç•¥ï¼ˆç›¸ä¼¼åº¦è¨ˆç®—ã€èšé¡ã€è·¨ç¾¤é¸æ“‡ï¼‰
    2. æ—©åœæª¢æŸ¥
    3. æ—¥èªŒè¨˜éŒ„
    4. æ—ç¾¤å„²å­˜ï¼ˆcluster_labelsï¼‰
    
    Returns:
        callback function with signature: callback(gen, pop, hof, logbook, record) -> dict or bool
    """
    # å„²å­˜ niching ç‹€æ…‹
    niching_state = {
        'niche_labels': None,
        'selected_k': None,
        'clusterer': None,
        'similarity_matrix': None
    }
    
    def callback(gen, pop, hof, logbook, record):
        """Generation callback - åœ¨æ¯ä»£è©•ä¼°å¾Œèª¿ç”¨"""
        gen_start_time = datetime.now()
        
        print(f"\n{'='*100}")
        print(f"ğŸ“Š Generation {gen}/{CONFIG['generations']}")
        print(f"{'='*100}")
        
        # ====================================================================
        # é¡¯ç¤ºçµ±è¨ˆ
        # ====================================================================
        min_fit = record['min']
        avg_fit = record['avg']
        max_fit = record['max']
        std_fit = record['std']
        
        print(f"\nğŸ“ˆ Fitness çµ±è¨ˆ:")
        print(f"   Min: {min_fit:.4f} ({min_fit*100:+.2f}%) | PnL: ${min_fit*CONFIG['initial_capital']:+,.0f}")
        print(f"   Avg: {avg_fit:.4f} ({avg_fit*100:+.2f}%) | PnL: ${avg_fit*CONFIG['initial_capital']:+,.0f}")
        print(f"   Max: {max_fit:.4f} ({max_fit*100:+.2f}%) | PnL: ${max_fit*CONFIG['initial_capital']:+,.0f}")
        print(f"   Std: {std_fit:.4f}")
        
        # è¨˜éŒ„åˆ°æ—¥èªŒ
        gen_log = {
            'generation': gen,
            'min_fitness': float(min_fit),
            'avg_fitness': float(avg_fit),
            'max_fitness': float(max_fit),
            'std_fitness': float(std_fit),
            'timestamp': datetime.now().isoformat()
        }
        evolution_log.append(gen_log)
        
        # ====================================================================
        # æ—©åœæª¢æŸ¥
        # ====================================================================
        if early_stopping is not None:
            current_best = hof[0].fitness.values[0]
            
            if early_stopping.step(current_best):
                print(f"\nâ¹ï¸  æ—©åœè§¸ç™¼ï¼")
                print(f"   é€£çºŒ {early_stopping.counter} ä»£ç„¡é¡¯è‘—é€²æ­¥")
                print(f"   æœ€ä½³ fitness: {early_stopping.best_fitness:.4f}")
                print(f"   æœ€çµ‚ generation: {gen}/{CONFIG['generations']}")
                
                # è¨˜éŒ„æ—©åœè³‡è¨Š
                gen_log['early_stopped'] = True
                gen_log['early_stop_reason'] = f'No improvement for {early_stopping.counter} generations'
                
                # å„²å­˜æœ€çµ‚æ—ç¾¤ï¼ˆå¸¶ cluster_labelsï¼‰
                _save_generation_with_niching(gen, pop, hof, record, niching_state, 
                                             generations_dir, CONFIG, is_final=True)
                
                return {'stop': True}  # åœæ­¢æ¼”åŒ–
            else:
                # é¡¯ç¤ºæ—©åœç‹€æ…‹
                if gen > 1:
                    print(f"\nâ¸ï¸  æ—©åœç‹€æ…‹: {early_stopping.counter}/{early_stopping.patience} ä»£ç„¡é€²æ­¥")
        
        # ====================================================================
        # å„²å­˜ç•¶å‰ä¸–ä»£çš„æ—ç¾¤ï¼ˆå¸¶ cluster_labelsï¼‰
        # ====================================================================
        _save_generation_with_niching(gen, pop, hof, record, niching_state, 
                                     generations_dir, CONFIG, is_final=False)
        
        # é¡¯ç¤ºæœ€ä½³å€‹é«”
        best_ind = hof[0]
        print(f"\nğŸ† ç•¶å‰æœ€ä½³å€‹é«”:")
        print(f"   Fitness: {best_ind.fitness.values[0]:.4f} ({best_ind.fitness.values[0]*100:+.2f}%)")
        print(f"   PnL: ${best_ind.fitness.values[0]*CONFIG['initial_capital']:+,.0f}")
        print(f"   æ·±åº¦: {best_ind.height}, ç¯€é»æ•¸: {len(best_ind)}")
        print(f"   è¦å‰‡: {str(best_ind)[:100]}{'...' if len(str(best_ind)) > 100 else ''}")
        
        # ====================================================================
        # Niching: è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£ä¸¦èšé¡ï¼ˆå¦‚æœå•Ÿç”¨ä¸”ä¸æ˜¯æœ€å¾Œä¸€ä»£ï¼‰
        # ====================================================================
        custom_selector = None
        
        if CONFIG['niching_enabled'] and gen < CONFIG['generations']:
            if gen % CONFIG['niching_update_frequency'] == 0:
                print(f"\nğŸ”¬ Niching: è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£...")
                sim_start = datetime.now()
                
                try:
                    # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
                    if len(pop) >= 200:
                        sim_matrix = ParallelSimilarityMatrix(pop, n_workers=8)
                        similarity_matrix = sim_matrix.compute(show_progress=False)
                    else:
                        sim_matrix = SimilarityMatrix(pop)
                        similarity_matrix = sim_matrix.compute(show_progress=False)
                    
                    sim_time = (datetime.now() - sim_start).total_seconds()
                    
                    print(f"   âœ“ ç›¸ä¼¼åº¦çŸ©é™£è¨ˆç®—å®Œæˆ ({sim_time:.1f}s)")
                    print(f"   å¹³å‡ç›¸ä¼¼åº¦: {sim_matrix.get_average_similarity():.4f}")
                    print(f"   å¤šæ¨£æ€§åˆ†æ•¸: {sim_matrix.get_diversity_score():.4f}")
                    
                    niching_state['similarity_matrix'] = similarity_matrix
                    
                    # å‹•æ…‹é¸æ“‡ k å€¼
                    if k_selector is not None:
                        print(f"\nğŸ¯ é¸æ“‡ K å€¼...")
                        k_result = k_selector.select_k(
                            similarity_matrix,
                            population_size=len(pop),
                            generation=gen,
                            fitness_values=[ind.fitness.values[0] for ind in pop]
                        )
                        
                        selected_k = k_result['selected_k']
                        niching_state['selected_k'] = selected_k
                        
                        print(f"   âœ“ é¸æ“‡ K = {selected_k}")
                        if 'reason' in k_result:
                            print(f"   åŸå› : {k_result['reason']}")
                    else:
                        selected_k = CONFIG['niching_n_clusters']
                        niching_state['selected_k'] = selected_k
                    
                    # èšé¡
                    print(f"\nğŸ¨ èšé¡ï¼ˆK={selected_k}ï¼‰...")
                    cluster_start = datetime.now()
                    
                    clusterer = NichingClusterer(
                        n_clusters=selected_k,
                        algorithm=CONFIG['niching_algorithm'],
                        random_state=42
                    )
                    
                    niche_labels = clusterer.fit_predict(similarity_matrix)
                    niching_state['niche_labels'] = niche_labels
                    niching_state['clusterer'] = clusterer
                    
                    cluster_time = (datetime.now() - cluster_start).total_seconds()
                    
                    print(f"   âœ“ èšé¡å®Œæˆ ({cluster_time:.1f}s)")
                    
                    # é¡¯ç¤ºèšé¡çµ±è¨ˆ
                    unique_labels, counts = np.unique(niche_labels, return_counts=True)
                    print(f"   Niche åˆ†å¸ƒ: {dict(zip(unique_labels.tolist(), counts.tolist()))}")
                    
                    if clusterer.silhouette_score_ is not None:
                        print(f"   Silhouette Score: {clusterer.silhouette_score_:.4f}")
                    
                    # è¨˜éŒ„ niching çµ±è¨ˆ
                    niching_log.append({
                        'generation': gen,
                        'n_clusters': int(selected_k),
                        'silhouette_score': float(clusterer.silhouette_score_) if clusterer.silhouette_score_ is not None else None,
                        'avg_similarity': float(sim_matrix.get_average_similarity()),
                        'diversity_score': float(sim_matrix.get_diversity_score()),
                        'niche_distribution': {int(k): int(v) for k, v in zip(unique_labels, counts)},
                        'computation_time': sim_time + cluster_time
                    })
                    
                    # å‰µå»ºè‡ªå®šç¾© selectorï¼ˆä½¿ç”¨è·¨ç¾¤é¸æ“‡ï¼‰
                    def niching_custom_selector(population, generation):
                        """ä½¿ç”¨ Niching çš„è‡ªå®šç¾©é¸æ“‡å™¨"""
                        print(f"\nğŸ¯ ä½¿ç”¨è·¨ç¾¤é¸æ“‡...")
                        try:
                            offspring = niching_selector.select(population, niching_state['niche_labels'], len(population))
                            
                            # é¡¯ç¤ºé¸æ“‡çµ±è¨ˆ
                            selection_stats = niching_selector.get_statistics()
                            print(f"   âœ“ é¸æ“‡å®Œæˆ")
                            print(f"   è·¨ç¾¤é…å°: {selection_stats['cross_niche_pairs']} ({selection_stats['cross_niche_ratio_actual']:.0%})")
                            print(f"   ç¾¤å…§é…å°: {selection_stats['within_niche_pairs']} ({selection_stats['within_niche_ratio_actual']:.0%})")
                            
                            # è¨˜éŒ„é¸æ“‡çµ±è¨ˆ
                            if evolution_log:
                                evolution_log[-1]['niching_selection'] = {
                                    'cross_niche_pairs': selection_stats['cross_niche_pairs'],
                                    'within_niche_pairs': selection_stats['within_niche_pairs'],
                                    'cross_niche_ratio': selection_stats['cross_niche_ratio_actual']
                                }
                            
                            return offspring
                        except Exception as e:
                            print(f"   âœ— è·¨ç¾¤é¸æ“‡å¤±æ•—: {e}")
                            import traceback
                            traceback.print_exc()
                            # å¤±æ•—æ™‚ä½¿ç”¨ tournament selection
                            return tools.selTournament(population, len(population), tournsize=CONFIG['tournament_size'])
                    
                    custom_selector = niching_custom_selector
                    
                except Exception as e:
                    print(f"   âœ— Niching å¤±æ•—: {e}")
                    import traceback
                    traceback.print_exc()
                    niching_state['niche_labels'] = None
        
        # é¡¯ç¤ºä¸–ä»£è€—æ™‚
        gen_time = (datetime.now() - gen_start_time).total_seconds()
        print(f"\nâ±ï¸  Generation {gen} è€—æ™‚: {gen_time:.1f}s")
        
        # è¿”å›çµæœ
        if custom_selector is not None:
            return {'custom_selector': custom_selector}
        else:
            return None  # ç¹¼çºŒä½¿ç”¨é»˜èª selector
    
    def _save_generation_with_niching(gen, pop, hof, record, niching_state, 
                                     generations_dir, CONFIG, is_final=False):
        """å„²å­˜æ—ç¾¤å¿«ç…§ï¼ˆåŒ…å« cluster_labelsï¼‰"""
        suffix = '_final' if is_final else ''
        gen_file = generations_dir / f"generation_{gen:03d}{suffix}.pkl"
        
        print(f"\nğŸ’¾ å„²å­˜ Generation {gen} æ—ç¾¤...")
        
        try:
            gen_data = {
                'generation': gen,
                'population': pop,
                'hall_of_fame': list(hof),
                'statistics': record,
                'timestamp': datetime.now().isoformat()
            }
            
            if is_final:
                gen_data['early_stopped'] = True
            
            # å¦‚æœæœ‰ niching è³‡è¨Šï¼Œä¸€ä½µå„²å­˜
            if CONFIG['niching_enabled'] and niching_state['niche_labels'] is not None:
                gen_data['cluster_labels'] = niching_state['niche_labels'].tolist() if hasattr(niching_state['niche_labels'], 'tolist') else list(niching_state['niche_labels'])
                gen_data['niching_info'] = {
                    'n_clusters': int(niching_state['selected_k']) if niching_state['selected_k'] is not None else CONFIG['niching_n_clusters'],
                    'algorithm': CONFIG['niching_algorithm'],
                    'silhouette_score': float(niching_state['clusterer'].silhouette_score_) if niching_state['clusterer'] is not None and niching_state['clusterer'].silhouette_score_ is not None else None
                }
            
            with open(gen_file, 'wb') as f:
                dill.dump(gen_data, f)
            
            file_size = gen_file.stat().st_size / (1024 * 1024)
            print(f"   âœ“ å·²å„²å­˜: {gen_file.name} ({file_size:.2f} MB)")
            
        except Exception as e:
            print(f"   âœ— å„²å­˜å¤±æ•—: {e}")
    
    return callback


def main():
    print("="*100)
    print("ğŸš€ Phase 1: Portfolio-Based GP Evolution Experiment")
    print("="*100)
    print()
    
    # ============================================================================
    # å¯¦é©—é…ç½®
    # ============================================================================
    
    CONFIG = {
        # è‚¡ç¥¨çµ„åˆ
        'tickers': ['ABX.TO', 'BBD-B.TO', 'RY.TO', 'TRP.TO'],
        
        # è¨“ç·´æœŸï¼ˆæ¨£æœ¬å…§ï¼‰
        'train_data_start': '1995-01-03',
        'train_backtest_start': '1997-06-25',
        'train_backtest_end': '1999-06-25',
        
        # æ¸¬è©¦æœŸï¼ˆæ¨£æœ¬å¤–ï¼‰
        'test_data_start': '1997-06-25',
        'test_backtest_start': '1999-06-26',
        'test_backtest_end': '2001-06-26',
        'initial_capital': 100000.0,
        
        # GP åƒæ•¸
        'population_size': 5000,
        'generations': 50,
        
        # æ¼”åŒ–åƒæ•¸
        'crossover_prob': 0.8,
        'mutation_prob': 0.2,
        'tournament_size': 3,
        
        # Fitness è¨ˆç®—æ–¹å¼
        'fitness_metric': 'excess_return',  # 'excess_return', 'sharpe_ratio', 'avg_sharpe'
        'risk_free_rate': 0.0,  # å¹´åŒ–ç„¡é¢¨éšªåˆ©ç‡
        
        # æ—©åœé…ç½®
        'early_stopping_enabled': True,      # æ˜¯å¦å•Ÿç”¨æ—©åœ
        'early_stopping_patience': 5,       # é€£çºŒç„¡é€²æ­¥çš„ä»£æ•¸
        'early_stopping_min_delta': 0.001,   # æœ€å°æ”¹é€²é–¾å€¼ï¼ˆæ ¹æ“š fitness_metric èª¿æ•´ï¼‰
        
        # Niching é…ç½®
        'niching_enabled': False,            # æ˜¯å¦å•Ÿç”¨ Niching ç­–ç•¥
        'niching_n_clusters': 3,            # Niche æ•¸é‡
        'niching_cross_ratio': 0.8,         # è·¨ç¾¤äº¤é…æ¯”ä¾‹ (0.8 = 80%)
        'niching_update_frequency': 1,      # æ¯ N ä»£é‡æ–°è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
        'niching_algorithm': 'kmeans',      # èšé¡æ¼”ç®—æ³• ('kmeans' æˆ– 'hierarchical')
        
        # è¼¸å‡ºç›®éŒ„
        'output_dir': 'portfolio_experiment_results',
        'experiment_name': f'portfolio_exp_sharpe_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
    }
    
    print("ğŸ“‹ å¯¦é©—é…ç½®:")
    print(f"  è‚¡ç¥¨çµ„åˆ: {', '.join(CONFIG['tickers'])}")
    print(f"\n  è¨“ç·´æœŸï¼ˆæ¨£æœ¬å…§ï¼‰:")
    print(f"    æ•¸æ“šæœŸé–“: {CONFIG['train_data_start']} åˆ° {CONFIG['train_backtest_start']}")
    print(f"    å›æ¸¬æœŸé–“: {CONFIG['train_backtest_start']} åˆ° {CONFIG['train_backtest_end']}")
    print(f"\n  æ¸¬è©¦æœŸï¼ˆæ¨£æœ¬å¤–ï¼‰:")
    print(f"    æ•¸æ“šæœŸé–“: {CONFIG['test_data_start']} åˆ° {CONFIG['test_backtest_start']}")
    print(f"    å›æ¸¬æœŸé–“: {CONFIG['test_backtest_start']} åˆ° {CONFIG['test_backtest_end']}")
    print(f"\n  åˆå§‹è³‡é‡‘: ${CONFIG['initial_capital']:,.0f}")
    print(f"  æ—ç¾¤å¤§å°: {CONFIG['population_size']}")
    print(f"  æ¼”åŒ–ä¸–ä»£: {CONFIG['generations']}")
    print(f"  Fitness æŒ‡æ¨™: {CONFIG['fitness_metric']}")
    if CONFIG['early_stopping_enabled']:
        print(f"  æ—©åœæ©Ÿåˆ¶: å•Ÿç”¨ï¼ˆpatience={CONFIG['early_stopping_patience']}, min_delta={CONFIG['early_stopping_min_delta']}ï¼‰")
    else:
        print(f"  æ—©åœæ©Ÿåˆ¶: åœç”¨")
    if CONFIG['niching_enabled']:
        print(f"  Niching ç­–ç•¥: å•Ÿç”¨")
        print(f"    - Niche æ•¸é‡: {CONFIG['niching_n_clusters']}")
        print(f"    - è·¨ç¾¤æ¯”ä¾‹: {CONFIG['niching_cross_ratio']:.0%}")
        print(f"    - æ›´æ–°é »ç‡: æ¯ {CONFIG['niching_update_frequency']} ä»£")
        print(f"    - èšé¡æ¼”ç®—æ³•: {CONFIG['niching_algorithm']}")
    else:
        print(f"  Niching ç­–ç•¥: åœç”¨")
    print()
    
    # ============================================================================
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    # ============================================================================
    
    exp_dir = Path(CONFIG['output_dir']) / CONFIG['experiment_name']
    exp_dir.mkdir(parents=True, exist_ok=True)
    
    # å‰µå»ºå­ç›®éŒ„
    generations_dir = exp_dir / "generations"
    generations_dir.mkdir(exist_ok=True)
    
    logs_dir = exp_dir / "logs"
    logs_dir.mkdir(exist_ok=True)
    
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {exp_dir}")
    print()
    
    # å„²å­˜é…ç½®
    with open(exp_dir / "config.json", 'w') as f:
        json.dump(CONFIG, f, indent=2)
    
    # ============================================================================
    # è¼‰å…¥æ•¸æ“š
    # ============================================================================
    
    print("1ï¸âƒ£  è¼‰å…¥å¸‚å ´æ•¸æ“š...")
    data = {}
    
    for ticker in CONFIG['tickers']:
        file_path = project_root / f"TSE300_selected/{ticker}.csv"
        if file_path.exists():
            df = pd.read_csv(file_path, index_col=0, parse_dates=True)
            data[ticker] = df
            print(f"   âœ“ {ticker}: {len(df)} å¤©")
        else:
            print(f"   âœ— {ticker}: æ–‡ä»¶ä¸å­˜åœ¨")
            sys.exit(1)
    
    print()
    
    # ============================================================================
    # å‰µå»ºè¨“ç·´å’Œæ¸¬è©¦ Engine
    # ============================================================================
    
    print("2ï¸âƒ£  åˆå§‹åŒ– Portfolio Backtesting Engines...")
    
    # è¨“ç·´ Engineï¼ˆæ¨£æœ¬å…§ï¼‰
    print("\n   è¨“ç·´æœŸ Engine:")
    try:
        train_engine = PortfolioBacktestingEngine(
            data=data,
            backtest_start=CONFIG['train_backtest_start'],
            backtest_end=CONFIG['train_backtest_end'],
            initial_capital=CONFIG['initial_capital'],
            pset=pset
        )
        print(f"     âœ“ åˆå§‹åŒ–æˆåŠŸ")
        print(f"     âœ“ äº¤æ˜“æ—¥æ•¸: {len(train_engine.common_dates)}")
        print(f"     âœ“ æ—¥æœŸç¯„åœ: {train_engine.common_dates[0].date()} åˆ° {train_engine.common_dates[-1].date()}")
    except Exception as e:
        print(f"     âœ— åˆå§‹åŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    # æ¸¬è©¦ Engineï¼ˆæ¨£æœ¬å¤–ï¼‰
    print("\n   æ¸¬è©¦æœŸ Engine:")
    try:
        test_engine = PortfolioBacktestingEngine(
            data=data,
            backtest_start=CONFIG['test_backtest_start'],
            backtest_end=CONFIG['test_backtest_end'],
            initial_capital=CONFIG['initial_capital'],
            pset=pset
        )
        print(f"     âœ“ åˆå§‹åŒ–æˆåŠŸ")
        print(f"     âœ“ äº¤æ˜“æ—¥æ•¸: {len(test_engine.common_dates)}")
        print(f"     âœ“ æ—¥æœŸç¯„åœ: {test_engine.common_dates[0].date()} åˆ° {test_engine.common_dates[-1].date()}")
    except Exception as e:
        print(f"     âœ— åˆå§‹åŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print()
    
    # ============================================================================
    # è¨­ç½® DEAP
    # ============================================================================
    
    # ============================================================================
    # è¨­ç½® DEAP ä¸¦é‹è¡Œæ¼”åŒ–
    # ============================================================================
    
    print("3ï¸âƒ£  è¨­ç½® DEAP ä¸¦é–‹å§‹æ¼”åŒ–...")
    
    # å‰µå»º Fitness å’Œ Individual é¡å‹
    if not hasattr(creator, "FitnessMax"):
        creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    if not hasattr(creator, "Individual"):
        creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessMax)
    
    print("   âœ“ DEAP é¡å‹å‰µå»ºå®Œæˆ")
    print()
    
    # ============================================================================
    # åˆå§‹åŒ– Niching å’Œæ—©åœæ©Ÿåˆ¶
    # ============================================================================
    
    # è¨˜éŒ„æ¼”åŒ–æ­·å²
    evolution_log = []
    niching_log = []
    
    # åˆå§‹åŒ–æ—©åœæ©Ÿåˆ¶
    early_stopping = None
    if CONFIG['early_stopping_enabled']:
        early_stopping = EarlyStopping(
            patience=CONFIG['early_stopping_patience'],
            min_delta=CONFIG['early_stopping_min_delta'],
            mode='max'  # Fitness è¶Šå¤§è¶Šå¥½
        )
        print(f"âœ“ æ—©åœæ©Ÿåˆ¶å·²å•Ÿç”¨ï¼ˆpatience={CONFIG['early_stopping_patience']}, min_delta={CONFIG['early_stopping_min_delta']}ï¼‰")
        print()
    
    # åˆå§‹åŒ– Niching æ©Ÿåˆ¶
    niching_selector = None
    k_selector = None
    
    if CONFIG['niching_enabled']:
        niching_selector = CrossNicheSelector(
            cross_niche_ratio=CONFIG['niching_cross_ratio'],
            tournament_size=CONFIG['tournament_size'],
            random_state=42
        )
        
        # å‰µå»º k å€¼é¸æ“‡å™¨
        k_selector = create_k_selector(CONFIG)
        
        print(f"âœ“ Niching ç­–ç•¥å·²å•Ÿç”¨")
        if 'niching_k_selection' in CONFIG:
            print(f"  - K å€¼é¸æ“‡: {CONFIG['niching_k_selection']} æ¨¡å¼")
            if CONFIG['niching_k_selection'] == 'calibration':
                print(f"  - æ ¡æº–æœŸ: å‰ {CONFIG.get('niching_k_calibration_gens', 3)} ä»£")
            print(f"  - K ç¯„åœ: [{CONFIG.get('niching_k_min', 2)}, {CONFIG.get('niching_k_max', 'auto')}]")
        else:
            print(f"  - Niche æ•¸é‡: {CONFIG['niching_n_clusters']} (å›ºå®š)")
        print(f"  - è·¨ç¾¤æ¯”ä¾‹: {CONFIG['niching_cross_ratio']:.0%}")
        print(f"  - æ›´æ–°é »ç‡: æ¯ {CONFIG['niching_update_frequency']} ä»£")
        print()
    
    # ============================================================================
    # å‰µå»º generation callback
    # ============================================================================
    
    generation_callback = create_generation_callback(
        CONFIG=CONFIG,
        early_stopping=early_stopping,
        niching_selector=niching_selector,
        k_selector=k_selector,
        generations_dir=generations_dir,
        evolution_log=evolution_log,
        niching_log=niching_log
    )
    
    # ============================================================================
    # é‹è¡Œæ¼”åŒ–ï¼ˆä½¿ç”¨ engine.pyï¼‰
    # ============================================================================
    
    print("4ï¸âƒ£  é–‹å§‹ GP æ¼”åŒ–...")
    print(f"   æ—ç¾¤å¤§å°: {CONFIG['population_size']}")
    print(f"   æ¼”åŒ–ä¸–ä»£: {CONFIG['generations']}")
    print(f"   Fitness æŒ‡æ¨™: {CONFIG['fitness_metric']}")
    print()
    print("="*100)
    
    start_time = datetime.now()
    
    # æº–å‚™è¨“ç·´æ•¸æ“šï¼ˆengine.py éœ€è¦çš„æ ¼å¼ï¼‰
    train_data = {
        ticker: {
            'data': df,
            'backtest_start': CONFIG['train_backtest_start'],
            'backtest_end': CONFIG['train_backtest_end']
        }
        for ticker, df in data.items()
    }
    
    # èª¿ç”¨ run_evolutionï¼ˆä¾†è‡ª engine.pyï¼‰
    population, logbook, hof = run_evolution(
        data=train_data,
        population_size=CONFIG['population_size'],
        n_generations=CONFIG['generations'],
        crossover_prob=CONFIG['crossover_prob'],
        mutation_prob=CONFIG['mutation_prob'],
        individual_records_dir=None,  # æˆ‘å€‘åœ¨ callback ä¸­è‡ªå·±è™•ç†å„²å­˜
        generation_callback=generation_callback,
        fitness_metric=CONFIG['fitness_metric'],
        tournament_size=CONFIG['tournament_size'],
        hof_size=10
    )
    
    total_time = (datetime.now() - start_time).total_seconds()
    actual_generations = len(evolution_log)  # å¯¦éš›é‹è¡Œçš„ä»£æ•¸
    
    print()
    print("="*100)
    print("âœ… æ¼”åŒ–å®Œæˆï¼")
    print("="*100)
    print()
    
    print(f"â±ï¸  ç¸½è€—æ™‚: {total_time/60:.2f} åˆ†é˜ ({total_time:.1f} ç§’)")
    print(f"ğŸ“Š ç¸½ä¸–ä»£æ•¸: {actual_generations}/{CONFIG['generations']}")
    
    # é¡¯ç¤ºæ—©åœè³‡è¨Š
    if early_stopping is not None and early_stopping.should_stop:
        print(f"â¹ï¸  æ—©åœ: æ˜¯ï¼ˆç¬¬ {actual_generations} ä»£è§¸ç™¼ï¼‰")
        print(f"   åŸå› : é€£çºŒ {early_stopping.patience} ä»£ç„¡é¡¯è‘—é€²æ­¥ï¼ˆmin_delta={early_stopping.min_delta}ï¼‰")
        print(f"   æœ€ä½³ fitness: {early_stopping.best_fitness:.4f}")
    else:
        print(f"â¹ï¸  æ—©åœ: å¦ï¼ˆå®Œæ•´é‹è¡Œï¼‰")
    
    print(f"âš¡ å¹³å‡æ¯ä»£: {total_time/actual_generations:.1f} ç§’")
    print()
    
    # ============================================================================
    # å„²å­˜æ¼”åŒ–æ—¥èªŒ
    # ============================================================================
    
    print("ğŸ’¾ å„²å­˜æ¼”åŒ–æ—¥èªŒ...")
    
    # å„²å­˜ JSON æ—¥èªŒ
    log_file = exp_dir / "evolution_log.json"
    log_data = {
        'config': CONFIG,
        'evolution_log': evolution_log,
        'total_time': total_time,
        'actual_generations': actual_generations,
        'final_statistics': {
            'best_fitness': float(hof[0].fitness.values[0]),
            'best_pnl': float(hof[0].fitness.values[0] * CONFIG['initial_capital'])
        }
    }
    
    # æ·»åŠ æ—©åœè³‡è¨Š
    if early_stopping is not None:
        log_data['early_stopping'] = {
            'enabled': True,
            'triggered': early_stopping.should_stop,
            'status': early_stopping.get_status()
        }
    else:
        log_data['early_stopping'] = {
            'enabled': False,
            'triggered': False
        }
    
    # æ·»åŠ  Niching è³‡è¨Š
    if CONFIG['niching_enabled']:
        log_data['niching'] = {
            'enabled': True,
            'n_clusters': CONFIG['niching_n_clusters'],
            'cross_ratio': CONFIG['niching_cross_ratio'],
            'update_frequency': CONFIG['niching_update_frequency'],
            'algorithm': CONFIG['niching_algorithm'],
            'log': niching_log
        }
    else:
        log_data['niching'] = {
            'enabled': False
        }
    
    with open(log_file, 'w') as f:
        json.dump(log_data, f, indent=2)
    print(f"   âœ“ {log_file}")
    
    # å„²å­˜ CSV æ—¥èªŒ
    log_df = pd.DataFrame(evolution_log)
    csv_file = exp_dir / "evolution_log.csv"
    log_df.to_csv(csv_file, index=False)
    print(f"   âœ“ {csv_file}")
    
    # ============================================================================
    # æœ€çµ‚åˆ†æ
    # ============================================================================
    
    print()
    print("="*100)
    print("ğŸ“Š æœ€çµ‚åˆ†æ")
    print("="*100)
    print()
    
    print("ğŸ† Top 10 æœ€ä½³å€‹é«”:")
    for i, ind in enumerate(hof, 1):
        fitness = ind.fitness.values[0]
        pnl = fitness * CONFIG['initial_capital']
        print(f"   {i:2d}. Fitness: {fitness:+.4f} ({fitness*100:+.2f}%) | "
              f"PnL: ${pnl:+,.0f} | "
              f"æ·±åº¦: {ind.height} | ç¯€é»: {len(ind)}")
    
    print()
    
    # è©³ç´°å›æ¸¬æœ€ä½³å€‹é«”
    print("ğŸ” è©³ç´°å›æ¸¬æœ€ä½³å€‹é«”...")
    best_individual = hof[0]
    
    # ========================================================================
    # è¨“ç·´æœŸï¼ˆæ¨£æœ¬å…§ï¼‰å›æ¸¬
    # ========================================================================
    print("\nğŸ“Š è¨“ç·´æœŸï¼ˆæ¨£æœ¬å…§ï¼‰ç¸¾æ•ˆ:")
    print("="*80)
    
    try:
        train_result = train_engine.backtest(best_individual)
        train_metrics = train_result['metrics']
        train_per_stock_pnl = train_result['per_stock_pnl']
        
        print(f"\nçµ„åˆç¸¾æ•ˆ:")
        print(f"  Total Return: {train_metrics['total_return']*100:.2f}%")
        print(f"  Sharpe Ratio: {train_metrics['sharpe_ratio']:.3f}")
        print(f"  Max Drawdown: {train_metrics['max_drawdown']*100:.2f}%")
        print(f"  Volatility: {train_metrics['volatility']*100:.2f}%")
        print(f"  Win Rate: {train_metrics['win_rate']*100:.2f}%")
        
        print(f"\nå„è‚¡ç¥¨ PnL è²¢ç»:")
        for ticker, pnl in train_per_stock_pnl.items():
            status = "âœ…" if pnl > 0 else "âŒ"
            print(f"  {ticker}: ${pnl:+,.2f} {status}")
        
        train_transactions = train_result['transactions']
        if len(train_transactions) > 0:
            buy_trades = len(train_transactions[train_transactions['action'] == 'BUY'])
            sell_trades = len(train_transactions[train_transactions['action'] == 'SELL'])
            print(f"\näº¤æ˜“çµ±è¨ˆ: ç¸½æ•¸ {len(train_transactions)} (è²·å…¥: {buy_trades}, è³£å‡º: {sell_trades})")
            
            # å„²å­˜è¨“ç·´æœŸäº¤æ˜“è¨˜éŒ„
            train_trades_file = exp_dir / "best_individual_train_trades.csv"
            train_transactions.to_csv(train_trades_file, index=False)
        
    except Exception as e:
        print(f"   âœ— è¨“ç·´æœŸå›æ¸¬å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    
    # ========================================================================
    # æ¸¬è©¦æœŸï¼ˆæ¨£æœ¬å¤–ï¼‰å›æ¸¬
    # ========================================================================
    print("\nğŸ“Š æ¸¬è©¦æœŸï¼ˆæ¨£æœ¬å¤–ï¼‰ç¸¾æ•ˆ:")
    print("="*80)
    
    try:
        test_result = test_engine.backtest(best_individual)
        test_metrics = test_result['metrics']
        test_per_stock_pnl = test_result['per_stock_pnl']
        
        print(f"\nçµ„åˆç¸¾æ•ˆ:")
        print(f"  Total Return: {test_metrics['total_return']*100:.2f}%")
        print(f"  Sharpe Ratio: {test_metrics['sharpe_ratio']:.3f}")
        print(f"  Max Drawdown: {test_metrics['max_drawdown']*100:.2f}%")
        print(f"  Volatility: {test_metrics['volatility']*100:.2f}%")
        print(f"  Win Rate: {test_metrics['win_rate']*100:.2f}%")
        
        print(f"\nå„è‚¡ç¥¨ PnL è²¢ç»:")
        for ticker, pnl in test_per_stock_pnl.items():
            status = "âœ…" if pnl > 0 else "âŒ"
            print(f"  {ticker}: ${pnl:+,.2f} {status}")
        
        test_transactions = test_result['transactions']
        if len(test_transactions) > 0:
            buy_trades = len(test_transactions[test_transactions['action'] == 'BUY'])
            sell_trades = len(test_transactions[test_transactions['action'] == 'SELL'])
            print(f"\näº¤æ˜“çµ±è¨ˆ: ç¸½æ•¸ {len(test_transactions)} (è²·å…¥: {buy_trades}, è³£å‡º: {sell_trades})")
            
            # å„²å­˜æ¸¬è©¦æœŸäº¤æ˜“è¨˜éŒ„
            test_trades_file = exp_dir / "best_individual_test_trades.csv"
            test_transactions.to_csv(test_trades_file, index=False)
        
        # ====================================================================
        # æ¯”è¼ƒè¨“ç·´æœŸ vs æ¸¬è©¦æœŸ
        # ====================================================================
        print("\nğŸ“ˆ è¨“ç·´æœŸ vs æ¸¬è©¦æœŸæ¯”è¼ƒ:")
        print("="*80)
        print(f"  {'æŒ‡æ¨™':<20} {'è¨“ç·´æœŸ':>15} {'æ¸¬è©¦æœŸ':>15} {'å·®ç•°':>15}")
        print(f"  {'-'*20} {'-'*15} {'-'*15} {'-'*15}")
        print(f"  {'Total Return':<20} {train_metrics['total_return']*100:>14.2f}% {test_metrics['total_return']*100:>14.2f}% {(test_metrics['total_return']-train_metrics['total_return'])*100:>+14.2f}%")
        print(f"  {'Sharpe Ratio':<20} {train_metrics['sharpe_ratio']:>15.3f} {test_metrics['sharpe_ratio']:>15.3f} {test_metrics['sharpe_ratio']-train_metrics['sharpe_ratio']:>+15.3f}")
        print(f"  {'Max Drawdown':<20} {train_metrics['max_drawdown']*100:>14.2f}% {test_metrics['max_drawdown']*100:>14.2f}% {(test_metrics['max_drawdown']-train_metrics['max_drawdown'])*100:>+14.2f}%")
        print(f"  {'Volatility':<20} {train_metrics['volatility']*100:>14.2f}% {test_metrics['volatility']*100:>14.2f}% {(test_metrics['volatility']-train_metrics['volatility'])*100:>+14.2f}%")
        
        # å„²å­˜å®Œæ•´çµæœ
        best_result_file = exp_dir / "best_individual_result.json"
        with open(best_result_file, 'w') as f:
            json.dump({
                'individual': str(best_individual),
                'train_fitness': float(best_individual.fitness.values[0]),
                'train_metrics': {k: float(v) if isinstance(v, (int, float, np.number)) else v 
                               for k, v in train_metrics.items()},
                'train_per_stock_pnl': {k: float(v) for k, v in train_per_stock_pnl.items()},
                'train_total_trades': len(train_transactions),
                'test_metrics': {k: float(v) if isinstance(v, (int, float, np.number)) else v 
                              for k, v in test_metrics.items()},
                'test_per_stock_pnl': {k: float(v) for k, v in test_per_stock_pnl.items()},
                'test_total_trades': len(test_transactions)
            }, f, indent=2)
        
        print(f"\nğŸ’¾ çµæœå·²å„²å­˜:")
        print(f"   âœ“ {best_result_file}")
        if len(train_transactions) > 0:
            print(f"   âœ“ {train_trades_file}")
        if len(test_transactions) > 0:
            print(f"   âœ“ {test_trades_file}")
        
    except Exception as e:
        print(f"   âœ— å›æ¸¬å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    
    print()
    print("="*100)
    print("ğŸ‰ å¯¦é©—å®Œæˆï¼")
    print("="*100)
    print()
    
    print(f"ğŸ“ æ‰€æœ‰çµæœå·²å„²å­˜è‡³: {exp_dir}")
    print(f"\nç›®éŒ„çµæ§‹:")
    print(f"  {exp_dir}/")
    print(f"  â”œâ”€â”€ config.json                         (å¯¦é©—é…ç½®)")
    print(f"  â”œâ”€â”€ evolution_log.json                  (æ¼”åŒ–æ—¥èªŒ)")
    print(f"  â”œâ”€â”€ evolution_log.csv                   (æ¼”åŒ–æ—¥èªŒ CSV)")
    print(f"  â”œâ”€â”€ best_individual_result.json         (æœ€ä½³å€‹é«”å®Œæ•´çµæœ)")
    print(f"  â”œâ”€â”€ best_individual_train_trades.csv    (è¨“ç·´æœŸäº¤æ˜“è¨˜éŒ„)")
    print(f"  â”œâ”€â”€ best_individual_test_trades.csv     (æ¸¬è©¦æœŸäº¤æ˜“è¨˜éŒ„)")
    print(f"  â””â”€â”€ generations/                        (æ—ç¾¤å¿«ç…§)")
    print(f"      â”œâ”€â”€ generation_001.pkl")
    print(f"      â”œâ”€â”€ generation_002.pkl")
    print(f"      â”œâ”€â”€ ...")
    print(f"      â””â”€â”€ generation_{CONFIG['generations']:03d}.pkl")
    print()

if __name__ == '__main__':
    main()
