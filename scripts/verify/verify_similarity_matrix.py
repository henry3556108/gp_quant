"""
Similarity Matrix é©—è­‰è…³æœ¬

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ SimilarityMatrix è¨ˆç®—æ—ç¾¤çš„ç›¸ä¼¼åº¦çŸ©é™£
"""

import sys
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from deap import gp, creator, base
from gp_quant.similarity import SimilarityMatrix, compute_similarity
import numpy as np


def setup_gp():
    """è¨­ç½® GP ç’°å¢ƒ"""
    # å‰µå»º fitness å’Œ individual é¡žåž‹
    if not hasattr(creator, "FitnessMax"):
        creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    if not hasattr(creator, "Individual"):
        creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessMax)
    
    # å‰µå»º primitive set
    pset = gp.PrimitiveSet("MAIN", arity=2)
    pset.addPrimitive(lambda x, y: x + y, 2, name="add")
    pset.addPrimitive(lambda x, y: x - y, 2, name="sub")
    pset.addPrimitive(lambda x, y: x * y, 2, name="mul")
    pset.addPrimitive(lambda x, y: x / y if y != 0 else 1, 2, name="div")
    
    pset.renameArguments(ARG0='x', ARG1='y')
    
    return pset


def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "=" * 80)
    print("Similarity Matrix é©—è­‰")
    print("=" * 80)
    
    # è¨­ç½® GP ç’°å¢ƒ
    pset = setup_gp()
    
    # å‰µå»º toolbox
    toolbox = base.Toolbox()
    toolbox.register("expr", gp.genHalfAndHalf, pset=pset, min_=1, max_=3)
    toolbox.register("individual", lambda: creator.Individual(toolbox.expr()))
    toolbox.register("population", lambda n: [toolbox.individual() for _ in range(n)])
    
    # ========================================================================
    # æ¸¬è©¦ 1: å°æ—ç¾¤ï¼ˆ10 å€‹å€‹é«”ï¼‰
    # ========================================================================
    print("\n" + "=" * 80)
    print("æ¸¬è©¦ 1: å°æ—ç¾¤ç›¸ä¼¼åº¦çŸ©é™£ï¼ˆ10 å€‹å€‹é«”ï¼‰")
    print("=" * 80)
    
    population_size = 10
    population = toolbox.population(n=population_size)
    
    print(f"\næ—ç¾¤å¤§å°: {population_size}")
    print(f"\nIndividual åˆ—è¡¨:")
    for i, ind in enumerate(population):
        print(f"  [{i}] {ind}")
    
    # å‰µå»º SimilarityMatrix
    print(f"\nè¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£...")
    sim_matrix = SimilarityMatrix(population)
    matrix = sim_matrix.compute(show_progress=True)
    
    # æ‰“å°çŸ©é™£
    print(f"\nç›¸ä¼¼åº¦çŸ©é™£:")
    sim_matrix.print_matrix(precision=4)
    
    # ç²å–çµ±è¨ˆè³‡è¨Š
    stats = sim_matrix.get_statistics()
    print(f"\nðŸ“Š çµ±è¨ˆè³‡è¨Š:")
    print(f"  æ—ç¾¤å¤§å°: {stats['population_size']}")
    print(f"  é…å°ç¸½æ•¸: {stats['total_pairs']}")
    print(f"  å¹³å‡ç›¸ä¼¼åº¦: {stats['mean_similarity']:.4f}")
    print(f"  æ¨™æº–å·®: {stats['std_similarity']:.4f}")
    print(f"  æœ€å°ç›¸ä¼¼åº¦: {stats['min_similarity']:.4f}")
    print(f"  æœ€å¤§ç›¸ä¼¼åº¦: {stats['max_similarity']:.4f}")
    print(f"  ä¸­ä½æ•¸: {stats['median_similarity']:.4f}")
    print(f"  å¤šæ¨£æ€§åˆ†æ•¸: {stats['diversity_score']:.4f}")
    
    # æœ€ç›¸ä¼¼çš„é…å°
    print(f"\nðŸ” æœ€ç›¸ä¼¼çš„ 3 å°å€‹é«”:")
    most_similar = sim_matrix.get_most_similar_pairs(n=3)
    for i, j, sim in most_similar:
        print(f"  Individual [{i}] vs [{j}]: {sim:.4f}")
        print(f"    [{i}] {population[i]}")
        print(f"    [{j}] {population[j]}")
    
    # æœ€ä¸ç›¸ä¼¼çš„é…å°
    print(f"\nðŸ” æœ€ä¸ç›¸ä¼¼çš„ 3 å°å€‹é«”:")
    least_similar = sim_matrix.get_least_similar_pairs(n=3)
    for i, j, sim in least_similar:
        print(f"  Individual [{i}] vs [{j}]: {sim:.4f}")
        print(f"    [{i}] {population[i]}")
        print(f"    [{j}] {population[j]}")
    
    # ========================================================================
    # æ¸¬è©¦ 2: ä¸­ç­‰æ—ç¾¤ï¼ˆ50 å€‹å€‹é«”ï¼‰
    # ========================================================================
    print("\n" + "=" * 80)
    print("æ¸¬è©¦ 2: ä¸­ç­‰æ—ç¾¤ç›¸ä¼¼åº¦çŸ©é™£ï¼ˆ50 å€‹å€‹é«”ï¼‰")
    print("=" * 80)
    
    population_size = 50
    population = toolbox.population(n=population_size)
    
    print(f"\næ—ç¾¤å¤§å°: {population_size}")
    print(f"é…å°ç¸½æ•¸: {population_size * (population_size - 1) // 2}")
    
    # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
    print(f"\nè¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£...")
    sim_matrix = SimilarityMatrix(population)
    matrix = sim_matrix.compute(show_progress=True)
    
    # ç²å–çµ±è¨ˆè³‡è¨Š
    stats = sim_matrix.get_statistics()
    print(f"\nðŸ“Š çµ±è¨ˆè³‡è¨Š:")
    print(f"  æ—ç¾¤å¤§å°: {stats['population_size']}")
    print(f"  é…å°ç¸½æ•¸: {stats['total_pairs']}")
    print(f"  å¹³å‡ç›¸ä¼¼åº¦: {stats['mean_similarity']:.4f}")
    print(f"  æ¨™æº–å·®: {stats['std_similarity']:.4f}")
    print(f"  æœ€å°ç›¸ä¼¼åº¦: {stats['min_similarity']:.4f}")
    print(f"  æœ€å¤§ç›¸ä¼¼åº¦: {stats['max_similarity']:.4f}")
    print(f"  ä¸­ä½æ•¸: {stats['median_similarity']:.4f}")
    print(f"  å¤šæ¨£æ€§åˆ†æ•¸: {stats['diversity_score']:.4f}")
    
    # ç›¸ä¼¼åº¦åˆ†ä½ˆ
    print(f"\nðŸ“ˆ ç›¸ä¼¼åº¦åˆ†ä½ˆ:")
    similarities = []
    for i in range(population_size):
        for j in range(i + 1, population_size):
            similarities.append(matrix[i][j])
    
    similarities = np.array(similarities)
    bins = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
    hist, _ = np.histogram(similarities, bins=bins)
    
    for i in range(len(bins) - 1):
        percentage = (hist[i] / len(similarities)) * 100
        bar = "â–ˆ" * int(percentage / 2)
        print(f"  [{bins[i]:.1f} - {bins[i+1]:.1f}]: {hist[i]:>5} ({percentage:>5.1f}%) {bar}")
    
    # ========================================================================
    # æ¸¬è©¦ 3: é©—è­‰å°ç¨±æ€§å’Œæ­£ç¢ºæ€§
    # ========================================================================
    print("\n" + "=" * 80)
    print("æ¸¬è©¦ 3: é©—è­‰çŸ©é™£æ€§è³ª")
    print("=" * 80)
    
    # é©—è­‰å°ç¨±æ€§
    is_symmetric = np.allclose(matrix, matrix.T)
    print(f"\nâœ“ å°ç¨±æ€§æª¢æŸ¥: {'é€šéŽ' if is_symmetric else 'å¤±æ•—'}")
    
    # é©—è­‰å°è§’ç·šç‚º 1
    diagonal_ones = np.allclose(np.diag(matrix), 1.0)
    print(f"âœ“ å°è§’ç·šç‚º 1: {'é€šéŽ' if diagonal_ones else 'å¤±æ•—'}")
    
    # é©—è­‰ç¯„åœ [0, 1]
    in_range = np.all((matrix >= 0) & (matrix <= 1))
    print(f"âœ“ ç¯„åœ [0, 1]: {'é€šéŽ' if in_range else 'å¤±æ•—'}")
    
    # éš¨æ©Ÿé©—è­‰å¹¾å€‹å€¼
    print(f"\nâœ“ éš¨æ©Ÿé©—è­‰:")
    for _ in range(3):
        i = np.random.randint(0, population_size)
        j = np.random.randint(0, population_size)
        if i != j:
            # ä½¿ç”¨ compute_similarity é‡æ–°è¨ˆç®—
            expected = compute_similarity(population[i], population[j])
            actual = matrix[i][j]
            match = np.isclose(expected, actual)
            print(f"  Individual [{i}] vs [{j}]: çŸ©é™£={actual:.4f}, é‡ç®—={expected:.4f} {'âœ“' if match else 'âœ—'}")
    
    # ========================================================================
    # ç¸½çµ
    # ========================================================================
    print("\n" + "=" * 80)
    print("âœ… ç¸½çµ")
    print("=" * 80)
    print("\nâœ¨ SimilarityMatrix åŠŸèƒ½é©—è­‰å®Œæˆï¼")
    print("\nåŠŸèƒ½ç‰¹é»ž:")
    print("  1. âœ… è¨ˆç®—æ—ç¾¤ç›¸ä¼¼åº¦çŸ©é™£")
    print("  2. âœ… æ”¯æ´ DEAP Individual")
    print("  3. âœ… å°ç¨±çŸ©é™£å„ªåŒ–")
    print("  4. âœ… é€²åº¦æ¢é¡¯ç¤º")
    print("  5. âœ… çµ±è¨ˆè³‡è¨Šè¨ˆç®—")
    print("  6. âœ… æœ€ç›¸ä¼¼/ä¸ç›¸ä¼¼é…å°æŸ¥è©¢")
    print("  7. âœ… å¤šæ¨£æ€§åˆ†æ•¸è¨ˆç®—")
    print("\næ€§èƒ½:")
    print(f"  - 10 å€‹å€‹é«”: 45 å°æ¯”è¼ƒ")
    print(f"  - 50 å€‹å€‹é«”: 1,225 å°æ¯”è¼ƒ")
    print(f"  - 100 å€‹å€‹é«”: 4,950 å°æ¯”è¼ƒ")
    print(f"  - 500 å€‹å€‹é«”: 124,750 å°æ¯”è¼ƒ")
    print("\nä¸‹ä¸€æ­¥:")
    print("  - å¯¦ä½œä¸¦è¡Œè¨ˆç®—åŠ é€Ÿå¤§è¦æ¨¡æ—ç¾¤ï¼ˆ5000+ å€‹é«”ï¼‰")
    print("  - å¯¦ä½œè¦–è¦ºåŒ–å·¥å…·ï¼ˆç†±åœ–ã€åˆ†ä½ˆåœ–ï¼‰")
    print("  - æ•´åˆåˆ° Niching ç­–ç•¥")
    print("\n" + "=" * 80)


if __name__ == "__main__":
    main()
