"""
é©—è­‰ä¸¦è¡Œç›¸ä¼¼åº¦çŸ©é™£è¨ˆç®—

æ¸¬è©¦ä¸¦è¡Œç‰ˆæœ¬çš„æ­£ç¢ºæ€§å’Œæ€§èƒ½ã€‚
"""

import sys
from pathlib import Path
import time
import numpy as np

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from deap import gp, creator, base
from gp_quant.gp.operators import pset
from gp_quant.similarity import SimilarityMatrix, ParallelSimilarityMatrix

# å‰µå»º DEAP fitness å’Œ individual
if not hasattr(creator, "FitnessMax"):
    creator.create("FitnessMax", base.Fitness, weights=(1.0,))
if not hasattr(creator, "Individual"):
    creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessMax)


def generate_population(size: int, max_depth: int = 5) -> list:
    """ç”Ÿæˆéš¨æ©Ÿæ—ç¾¤"""
    toolbox = base.Toolbox()
    toolbox.register("expr", gp.genHalfAndHalf, pset=pset, min_=1, max_=max_depth)
    toolbox.register("individual", lambda: creator.Individual(toolbox.expr()))
    toolbox.register("population", lambda n: [toolbox.individual() for _ in range(n)])
    
    return toolbox.population(size)


def test_correctness(pop_size=30):
    """æ¸¬è©¦ä¸¦è¡Œç‰ˆæœ¬çš„æ­£ç¢ºæ€§"""
    print("="*80)
    print(f"æ¸¬è©¦ 1: æ­£ç¢ºæ€§é©—è­‰ï¼ˆpopulation={pop_size}ï¼‰")
    print("="*80)
    print()
    
    # ç”Ÿæˆæ—ç¾¤
    print(f"ç”Ÿæˆ {pop_size} å€‹å€‹é«”...")
    population = generate_population(pop_size)
    print(f"âœ“ æ—ç¾¤ç”Ÿæˆå®Œæˆ")
    print()
    
    # åºåˆ—è¨ˆç®—
    print("åºåˆ—è¨ˆç®—...")
    start = time.time()
    sim_matrix_seq = SimilarityMatrix(population)
    matrix_seq = sim_matrix_seq.compute(show_progress=True)
    time_seq = time.time() - start
    print(f"âœ“ åºåˆ—è¨ˆç®—å®Œæˆ: {time_seq:.2f}s")
    print()
    
    # ä¸¦è¡Œè¨ˆç®—
    print("ä¸¦è¡Œè¨ˆç®—...")
    start = time.time()
    sim_matrix_par = ParallelSimilarityMatrix(population)
    matrix_par = sim_matrix_par.compute(show_progress=True)
    time_par = time.time() - start
    print(f"âœ“ ä¸¦è¡Œè¨ˆç®—å®Œæˆ: {time_par:.2f}s")
    print()
    
    # æ¯”è¼ƒçµæœ
    print("æ¯”è¼ƒçµæœ...")
    diff = np.abs(matrix_seq - matrix_par)
    max_diff = np.max(diff)
    mean_diff = np.mean(diff)
    
    print(f"  æœ€å¤§å·®ç•°: {max_diff:.10f}")
    print(f"  å¹³å‡å·®ç•°: {mean_diff:.10f}")
    
    if max_diff < 1e-10:
        print("  âœ… çµæœå®Œå…¨ä¸€è‡´ï¼")
    else:
        print(f"  âš ï¸  çµæœæœ‰å¾®å°å·®ç•°ï¼ˆå¯èƒ½æ˜¯æµ®é»èª¤å·®ï¼‰")
    print()
    
    # çµ±è¨ˆè³‡è¨Š
    stats_seq = sim_matrix_seq.get_statistics()
    stats_par = sim_matrix_par.get_statistics()
    
    print("çµ±è¨ˆè³‡è¨Šæ¯”è¼ƒ:")
    print(f"  å¹³å‡ç›¸ä¼¼åº¦: åºåˆ—={stats_seq.get('mean_similarity', stats_seq.get('mean')):.4f}, ä¸¦è¡Œ={stats_par.get('mean_similarity', stats_par.get('mean')):.4f}")
    print(f"  å¤šæ¨£æ€§åˆ†æ•¸: åºåˆ—={stats_seq['diversity_score']:.4f}, ä¸¦è¡Œ={stats_par['diversity_score']:.4f}")
    print()
    
    # åŠ é€Ÿæ¯”
    speedup = time_seq / time_par
    print(f"âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
    print()
    
    return max_diff < 1e-6


def test_performance():
    """æ¸¬è©¦ä¸åŒæ—ç¾¤å¤§å°çš„æ€§èƒ½"""
    print("="*80)
    print("æ¸¬è©¦ 2: æ€§èƒ½æ¸¬è©¦")
    print("="*80)
    print()
    
    sizes = [50, 100, 200, 500, 2000]
    results = []
    
    for size in sizes:
        print(f"\n{'='*80}")
        print(f"Population Size: {size}")
        print(f"{'='*80}")
        
        # ç”Ÿæˆæ—ç¾¤
        print(f"ç”Ÿæˆ {size} å€‹å€‹é«”...")
        population = generate_population(size, max_depth=4)
        print(f"âœ“ æ—ç¾¤ç”Ÿæˆå®Œæˆ")
        print()
        
        # åºåˆ—è¨ˆç®—
        print("åºåˆ—è¨ˆç®—...")
        start = time.time()
        sim_matrix_seq = SimilarityMatrix(population)
        matrix_seq = sim_matrix_seq.compute(show_progress=False)
        time_seq = time.time() - start
        print(f"âœ“ åºåˆ—è¨ˆç®—å®Œæˆ: {time_seq:.2f}s")
        
        # ä¸¦è¡Œè¨ˆç®—
        print("ä¸¦è¡Œè¨ˆç®—...")
        start = time.time()
        sim_matrix_par = ParallelSimilarityMatrix(population)
        matrix_par = sim_matrix_par.compute(show_progress=False)
        time_par = time.time() - start
        print(f"âœ“ ä¸¦è¡Œè¨ˆç®—å®Œæˆ: {time_par:.2f}s")
        
        # åŠ é€Ÿæ¯”
        speedup = time_seq / time_par
        print(f"âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
        
        # çµ±è¨ˆ
        stats = sim_matrix_par.get_statistics()
        avg_sim = stats.get('mean_similarity', stats.get('mean', 0))
        print(f"ğŸ“Š å¹³å‡ç›¸ä¼¼åº¦: {avg_sim:.4f}")
        print(f"ğŸ“Š å¤šæ¨£æ€§åˆ†æ•¸: {stats['diversity_score']:.4f}")
        
        results.append({
            'size': size,
            'time_seq': time_seq,
            'time_par': time_par,
            'speedup': speedup,
            'avg_similarity': avg_sim
        })
    
    # ç¸½çµ
    print("\n" + "="*80)
    print("æ€§èƒ½ç¸½çµ")
    print("="*80)
    print()
    print(f"{'Size':<10} {'åºåˆ—(s)':<12} {'ä¸¦è¡Œ(s)':<12} {'åŠ é€Ÿæ¯”':<10} {'å¹³å‡ç›¸ä¼¼åº¦':<12}")
    print("-"*80)
    for r in results:
        print(f"{r['size']:<10} {r['time_seq']:<12.2f} {r['time_par']:<12.2f} {r['speedup']:<10.2f}x {r['avg_similarity']:<12.4f}")
    print()
    
    # å¹³å‡åŠ é€Ÿæ¯”
    avg_speedup = np.mean([r['speedup'] for r in results])
    print(f"å¹³å‡åŠ é€Ÿæ¯”: {avg_speedup:.2f}x")
    print()
    
    return results


def test_large_population():
    """æ¸¬è©¦å¤§æ—ç¾¤ï¼ˆ1000ï¼‰"""
    print("="*80)
    print("æ¸¬è©¦ 3: å¤§æ—ç¾¤æ¸¬è©¦ï¼ˆpopulation=1000ï¼‰")
    print("="*80)
    print()
    
    size = 1000
    print(f"ç”Ÿæˆ {size} å€‹å€‹é«”...")
    population = generate_population(size, max_depth=4)
    print(f"âœ“ æ—ç¾¤ç”Ÿæˆå®Œæˆ")
    print()
    
    # åªæ¸¬è©¦ä¸¦è¡Œç‰ˆæœ¬ï¼ˆåºåˆ—ç‰ˆæœ¬å¤ªæ…¢ï¼‰
    print("ä¸¦è¡Œè¨ˆç®—...")
    start = time.time()
    sim_matrix_par = ParallelSimilarityMatrix(population, n_workers=8)
    matrix_par = sim_matrix_par.compute(show_progress=True)
    time_par = time.time() - start
    print(f"âœ“ ä¸¦è¡Œè¨ˆç®—å®Œæˆ: {time_par:.2f}s ({time_par/60:.1f} åˆ†é˜)")
    print()
    
    # çµ±è¨ˆ
    stats = sim_matrix_par.get_statistics()
    print("çµ±è¨ˆè³‡è¨Š:")
    print(f"  å¹³å‡ç›¸ä¼¼åº¦: {stats.get('mean_similarity', stats.get('mean', 0)):.4f}")
    print(f"  æ¨™æº–å·®: {stats.get('std_similarity', stats.get('std', 0)):.4f}")
    print(f"  æœ€å°å€¼: {stats.get('min_similarity', stats.get('min', 0)):.4f}")
    print(f"  æœ€å¤§å€¼: {stats.get('max_similarity', stats.get('max', 0)):.4f}")
    print(f"  å¤šæ¨£æ€§åˆ†æ•¸: {stats['diversity_score']:.4f}")
    print()
    
    # æœ€ç›¸ä¼¼å’Œæœ€ä¸ç›¸ä¼¼çš„é…å°
    print("æœ€ç›¸ä¼¼çš„ 5 å°:")
    most_similar = sim_matrix_par.get_most_similar_pairs(top_k=5)
    for i, j, sim in most_similar:
        print(f"  [{i}, {j}]: {sim:.4f}")
    print()
    
    print("æœ€ä¸ç›¸ä¼¼çš„ 5 å°:")
    most_dissimilar = sim_matrix_par.get_most_dissimilar_pairs(top_k=5)
    for i, j, sim in most_dissimilar:
        print(f"  [{i}, {j}]: {sim:.4f}")
    print()
    
    return time_par


def main():
    print("\n" + "="*80)
    print("ä¸¦è¡Œç›¸ä¼¼åº¦çŸ©é™£è¨ˆç®—é©—è­‰")
    print("="*80)
    print()
    
    # æ¸¬è©¦ 1: æ­£ç¢ºæ€§
    correct = test_correctness(pop_size=30)
    
    if not correct:
        print("âŒ æ­£ç¢ºæ€§æ¸¬è©¦å¤±æ•—ï¼")
        return
    
    print("âœ… æ­£ç¢ºæ€§æ¸¬è©¦é€šéï¼")
    print()
    
    # æ¸¬è©¦ 2: æ€§èƒ½
    results = test_performance()
    
    # æ¸¬è©¦ 3: å¤§æ—ç¾¤
    time_1000 = test_large_population()
    
    # æœ€çµ‚ç¸½çµ
    print("="*80)
    print("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
    print("="*80)
    print()
    
    print("ä¸»è¦ç™¼ç¾:")
    print(f"  1. ä¸¦è¡Œç‰ˆæœ¬çµæœèˆ‡åºåˆ—ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ âœ…")
    print(f"  2. å¹³å‡åŠ é€Ÿæ¯”: {np.mean([r['speedup'] for r in results]):.2f}x")
    print(f"  3. Population=1000 è¨ˆç®—æ™‚é–“: {time_1000:.1f}s ({time_1000/60:.1f} åˆ†é˜)")
    print()
    
    print("å»ºè­°:")
    print("  - Population < 100: ä½¿ç”¨ SimilarityMatrixï¼ˆåºåˆ—ç‰ˆæœ¬ï¼‰")
    print("  - Population >= 100: ä½¿ç”¨ ParallelSimilarityMatrixï¼ˆä¸¦è¡Œç‰ˆæœ¬ï¼‰")
    print("  - Population >= 1000: å»ºè­°æ¯ 10-15 ä»£æ›´æ–°ä¸€æ¬¡ç›¸ä¼¼åº¦çŸ©é™£")
    print()


if __name__ == "__main__":
    main()
