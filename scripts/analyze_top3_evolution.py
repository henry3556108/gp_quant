#!/usr/bin/env python3
"""
Top3 å€‹é«”æ¼”åŒ–åˆ†æè…³æœ¬ - åˆ†ææ¯ä¸–ä»£å‰ä¸‰åå€‹é«”çš„å›æ¸¬ç¸¾æ•ˆ
"""
import argparse
import json
import pickle
import tempfile
from pathlib import Path
from datetime import datetime
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from gp_quant.data.loader import load_and_process_data
from gp_quant.evolution.components.loader import EvolutionLoader
from gp_quant.backtesting.portfolio_engine import PortfolioBacktestingEngine


def setup_deap_creator():
    """åˆå§‹åŒ– DEAP creator"""
    from deap import creator, base
    
    # æª¢æŸ¥æ˜¯å¦å·²ç¶“å‰µå»º
    if not hasattr(creator, 'FitnessMax'):
        creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    
    if not hasattr(creator, 'Individual'):
        from deap import gp
        creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessMax)


def run_backtest_for_individual(individual, train_data, test_data, config):
    """
    ç‚ºå–®å€‹å€‹é«”é‹è¡Œå®Œæ•´å›æ¸¬
    
    Args:
        individual: è¦å›æ¸¬çš„å€‹é«”
        train_data: è¨“ç·´æ•¸æ“š
        test_data: æ¸¬è©¦æ•¸æ“š
        config: é…ç½®
        
    Returns:
        åŒ…å«è¨“ç·´å’Œæ¸¬è©¦çµæœçš„å­—å…¸
    """
    from gp_quant.evolution.components.gp import pset
    
    results = {
        'individual_id': individual.id,
        'fitness': individual.fitness.values[0] if hasattr(individual.fitness, 'values') and individual.fitness.values else None,
        'tree_size': len(individual),
        'tree_depth': individual.height,
        'tree_expression': str(individual),
        'train_backtest': None,
        'test_backtest': None
    }
    
    # è¨“ç·´æ•¸æ“šå›æ¸¬
    try:
        # è™•ç†æ•¸æ“šæ ¼å¼ - æå– DataFrame
        processed_train_data = {}
        for ticker, ticker_data in train_data.items():
            if isinstance(ticker_data, dict) and 'data' in ticker_data:
                processed_train_data[ticker] = ticker_data['data']
            else:
                processed_train_data[ticker] = ticker_data
        
        train_engine = PortfolioBacktestingEngine(
            data=processed_train_data,
            backtest_start=config['data']['train_backtest_start'],
            backtest_end=config['data']['train_backtest_end'],
            initial_capital=100000.0,
            pset=pset
        )
        
        train_results = train_engine.backtest(individual)
        
        # å¾ equity_curve æå–æ•¸æ“š
        equity_curve = train_results.get('equity_curve')
        if equity_curve is not None and len(equity_curve) > 0:
            portfolio_values = equity_curve.values.tolist()
            dates = equity_curve.index.tolist()
        else:
            portfolio_values = []
            dates = []
        
        results['train_backtest'] = {
            'fitness': train_results['metrics']['excess_return'],
            'metrics': train_results['metrics'],
            'portfolio_values': portfolio_values,
            'dates': dates,
            'equity_curve': equity_curve
        }
        
    except Exception as e:
        print(f"   âš ï¸ è¨“ç·´å›æ¸¬å¤±æ•—: {e}")
        results['train_backtest'] = {'error': str(e)}
    
    # æ¸¬è©¦æ•¸æ“šå›æ¸¬
    try:
        # è™•ç†æ•¸æ“šæ ¼å¼ - æå– DataFrame
        processed_test_data = {}
        for ticker, ticker_data in test_data.items():
            if isinstance(ticker_data, dict) and 'data' in ticker_data:
                processed_test_data[ticker] = ticker_data['data']
            else:
                processed_test_data[ticker] = ticker_data
        
        test_engine = PortfolioBacktestingEngine(
            data=processed_test_data,
            backtest_start=config['data']['test_backtest_start'],
            backtest_end=config['data']['test_backtest_end'],
            initial_capital=100000.0,
            pset=pset
        )
        
        test_results = test_engine.backtest(individual)
        
        # å¾ equity_curve æå–æ•¸æ“š
        equity_curve = test_results.get('equity_curve')
        if equity_curve is not None and len(equity_curve) > 0:
            portfolio_values = equity_curve.values.tolist()
            dates = equity_curve.index.tolist()
        else:
            portfolio_values = []
            dates = []
        
        results['test_backtest'] = {
            'fitness': test_results['metrics']['excess_return'],
            'metrics': test_results['metrics'],
            'portfolio_values': portfolio_values,
            'dates': dates,
            'equity_curve': equity_curve
        }
        
    except Exception as e:
        print(f"   âš ï¸ æ¸¬è©¦å›æ¸¬å¤±æ•—: {e}")
        results['test_backtest'] = {'error': str(e)}
    
    return results


def plot_individual_performance(individual_results, output_dir, generation, rank):
    """
    ç¹ªè£½å–®å€‹å€‹é«”çš„ç¸¾æ•ˆåœ–è¡¨
    
    Args:
        individual_results: å€‹é«”å›æ¸¬çµæœ
        output_dir: è¼¸å‡ºç›®éŒ„
        generation: ä¸–ä»£
        rank: æ’å
    """
    individual_id = individual_results['individual_id']
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle(f'Gen {generation} Rank {rank} - Individual {individual_id[:8]}...\n'
                f'Fitness: {individual_results["fitness"]:.6f} | '
                f'Tree: {individual_results["tree_size"]} nodes, depth {individual_results["tree_depth"]}', 
                fontsize=14, fontweight='bold')
    
    # è¨­ç½®ä¸­æ–‡å­—é«”
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    # è¨“ç·´æ•¸æ“šç¸¾æ•ˆ
    train_data = individual_results.get('train_backtest')
    if train_data and 'portfolio_values' in train_data and train_data['portfolio_values']:
        portfolio_values = train_data['portfolio_values']
        dates = train_data['dates']
        
        # æŠ•è³‡çµ„åˆåƒ¹å€¼
        axes[0, 0].plot(dates, portfolio_values, 'b-', linewidth=2)
        axes[0, 0].set_title(f'Training Portfolio Value\nFitness: {train_data["fitness"]:.6f}')
        axes[0, 0].set_ylabel('Portfolio Value ($)')
        axes[0, 0].grid(True, alpha=0.3)
        
        # ç´¯ç©å ±é…¬
        cumulative_returns = (np.array(portfolio_values) / portfolio_values[0] - 1) * 100
        axes[0, 1].plot(dates, cumulative_returns, 'g-', linewidth=2)
        axes[0, 1].set_title('Training Cumulative Returns')
        axes[0, 1].set_ylabel('Return (%)')
        axes[0, 1].grid(True, alpha=0.3)
        
        # é¡¯ç¤ºæŒ‡æ¨™
        metrics = train_data.get('metrics', {})
        axes[0, 0].text(0.02, 0.98, 
                       f"Total Return: {metrics.get('total_return', 0):.2f}%\n"
                       f"Sharpe: {metrics.get('sharpe_ratio', 0):.3f}\n"
                       f"Max DD: {metrics.get('max_drawdown', 0):.2f}%",
                       transform=axes[0, 0].transAxes, verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    else:
        axes[0, 0].text(0.5, 0.5, 'No Training Data', ha='center', va='center', transform=axes[0, 0].transAxes)
        axes[0, 1].text(0.5, 0.5, 'No Training Data', ha='center', va='center', transform=axes[0, 1].transAxes)
    
    # æ¸¬è©¦æ•¸æ“šç¸¾æ•ˆ
    test_data = individual_results.get('test_backtest')
    if test_data and 'portfolio_values' in test_data and test_data['portfolio_values']:
        portfolio_values = test_data['portfolio_values']
        # æå–ç¸¾æ•ˆæ•¸æ“š
        performance_data = None
        try:
            # å¾å›æ¸¬çµæœä¸­æå–ç¸¾æ•ˆæ•¸æ“š - ä½¿ç”¨ equity_curve
            equity_curve = test_data.get('equity_curve')
            
            if equity_curve is not None and len(equity_curve) > 0:
                # equity_curve æ˜¯ä¸€å€‹ pandas Seriesï¼Œç´¢å¼•æ˜¯æ—¥æœŸ
                dates = equity_curve.index.tolist()
                portfolio_values = equity_curve.values.tolist()
                
                performance_data = {
                    'dates': dates,
                    'portfolio_values': portfolio_values,
                    'returns': np.diff(portfolio_values) / portfolio_values[:-1],
                    'cumulative_returns': (np.array(portfolio_values) / portfolio_values[0] - 1) * 100
                }
                
                print(f"   ğŸ“Š ç¸¾æ•ˆæ•¸æ“š: {len(dates)} å€‹äº¤æ˜“æ—¥")
                print(f"   ğŸ’° æœ€çµ‚åƒ¹å€¼: ${portfolio_values[-1]:,.2f}")
                print(f"   ğŸ“ˆ ç¸½å ±é…¬: {performance_data['cumulative_returns'][-1]:.2f}%")
                
                # é¡¯ç¤ºå…¶ä»–æŒ‡æ¨™
                metrics = test_data.get('metrics', {})
                print(f"   ğŸ“ˆ ç¸½æ”¶ç›Šç‡: {metrics.get('total_return', 0):.2f}%")
                print(f"   ğŸ“Š å¤æ™®æ¯”ç‡: {metrics.get('sharpe_ratio', 0):.4f}")
                print(f"   ğŸ“‰ æœ€å¤§å›æ’¤: {metrics.get('max_drawdown', 0):.2f}%")
                
                # æª¢æŸ¥æ˜¯å¦æœ‰äº¤æ˜“
                transactions = test_data.get('transactions')
                if transactions is not None and len(transactions) > 0:
                    print(f"   ğŸ’¼ äº¤æ˜“æ¬¡æ•¸: {len(transactions)}")
                else:
                    print(f"   âš ï¸ è­¦å‘Š: æ²’æœ‰ç”¢ç”Ÿä»»ä½•äº¤æ˜“ä¿¡è™Ÿ")
            else:
                print(f"   âš ï¸ ç„¡æ³•æå– equity_curve")
            
        except Exception as e:
            print(f"   âš ï¸ ç„¡æ³•æå–è©³ç´°ç¸¾æ•ˆæ•¸æ“š: {e}")
            import traceback
            traceback.print_exc()
        
        # æŠ•è³‡çµ„åˆåƒ¹å€¼
        axes[1, 0].plot(performance_data['dates'], performance_data['portfolio_values'], 'r-', linewidth=2)
        axes[1, 0].set_title(f'Test Portfolio Value\nFitness: {test_data["fitness"]:.6f}')
        axes[1, 0].set_ylabel('Portfolio Value ($)')
        axes[1, 0].grid(True, alpha=0.3)
        
        # ç´¯ç©å ±é…¬
        axes[1, 1].plot(performance_data['dates'], performance_data['cumulative_returns'], 'orange', linewidth=2)
        axes[1, 1].set_title('Test Cumulative Returns')
        axes[1, 1].set_ylabel('Return (%)')
        axes[1, 1].grid(True, alpha=0.3)
        
        # é¡¯ç¤ºæŒ‡æ¨™
        metrics = test_data.get('metrics', {})
        axes[1, 0].text(0.02, 0.98, 
                       f"Total Return: {metrics.get('total_return', 0):.2f}%\n"
                       f"Sharpe: {metrics.get('sharpe_ratio', 0):.3f}\n"
                       f"Max DD: {metrics.get('max_drawdown', 0):.2f}%",
                       transform=axes[1, 0].transAxes, verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))
    else:
        axes[1, 0].text(0.5, 0.5, 'No Test Data', ha='center', va='center', transform=axes[1, 0].transAxes)
        axes[1, 1].text(0.5, 0.5, 'No Test Data', ha='center', va='center', transform=axes[1, 1].transAxes)
    
    plt.tight_layout()
    
    # ä¿å­˜åœ–è¡¨
    plot_file = output_dir / f"gen_{generation:02d}_rank_{rank}_individual_{individual_id[:8]}.png"
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    plt.close()  # é—œé–‰åœ–è¡¨ä»¥ç¯€çœè¨˜æ†¶é«”
    
    return plot_file


def analyze_top3_evolution(records_dir: str, config: dict, train_data: dict, test_data: dict, 
                          generate_plots: bool = True, top_n: int = 3):
    """
    åˆ†ææ¯ä¸–ä»£ Top N å€‹é«”çš„æ¼”åŒ–éç¨‹
    
    Args:
        records_dir: è¨˜éŒ„ç›®éŒ„
        config: é…ç½®
        train_data: è¨“ç·´æ•¸æ“š
        test_data: æ¸¬è©¦æ•¸æ“š
        generate_plots: æ˜¯å¦ç”Ÿæˆç¸¾æ•ˆåœ–è¡¨
        top_n: åˆ†æå‰Nåå€‹é«”
    """
    print(f"ğŸ“Š é–‹å§‹åˆ†ææ¯ä¸–ä»£ Top{top_n} å€‹é«”æ¼”åŒ–éç¨‹...")
    
    loader = EvolutionLoader(records_dir)
    available_generations = loader.get_available_generations()
    
    if not available_generations:
        print("âŒ æ²’æœ‰å¯ç”¨çš„ä¸–ä»£æ•¸æ“š")
        return
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = Path(records_dir) / "top3_analysis"
    output_dir.mkdir(exist_ok=True)
    
    if generate_plots:
        plots_dir = output_dir / "plots"
        plots_dir.mkdir(exist_ok=True)
    
    all_results = []
    
    for generation in available_generations:
        print(f"\nğŸ”„ åˆ†æä¸–ä»£ {generation}...")
        
        try:
            # è¼‰å…¥æ—ç¾¤
            population = loader.load_population(generation)
            
            # æ‰¾åˆ°æœ‰æ•ˆå€‹é«”ä¸¦æ’åº
            valid_individuals = [ind for ind in population 
                               if hasattr(ind.fitness, 'values') and ind.fitness.values]
            
            if len(valid_individuals) < top_n:
                print(f"   âš ï¸ ä¸–ä»£ {generation} åªæœ‰ {len(valid_individuals)} å€‹æœ‰æ•ˆå€‹é«”")
                continue
            
            # æŒ‰é©æ‡‰åº¦æ’åºï¼Œå–å‰Nå
            top_individuals = sorted(valid_individuals, 
                                   key=lambda ind: ind.fitness.values[0], 
                                   reverse=True)[:top_n]
            
            generation_results = []
            
            for rank, individual in enumerate(top_individuals, 1):
                print(f"   ğŸ“ˆ åˆ†æç¬¬ {rank} åå€‹é«” (ID: {individual.id[:8]}..., "
                      f"Fitness: {individual.fitness.values[0]:.6f})")
                
                # é‹è¡Œå›æ¸¬
                individual_results = run_backtest_for_individual(
                    individual, train_data, test_data, config)
                individual_results['generation'] = generation
                individual_results['rank'] = rank
                
                # ç”Ÿæˆç¸¾æ•ˆåœ–è¡¨
                if generate_plots:
                    plot_file = plot_individual_performance(
                        individual_results, plots_dir, generation, rank)
                    individual_results['plot_file'] = str(plot_file)
                    print(f"      ğŸ“Š ç¸¾æ•ˆåœ–è¡¨å·²ä¿å­˜: {plot_file.name}")
                
                generation_results.append(individual_results)
            
            all_results.extend(generation_results)
            
        except Exception as e:
            print(f"   âŒ ä¸–ä»£ {generation} åˆ†æå¤±æ•—: {e}")
            continue
    
    # ä¿å­˜å®Œæ•´çµæœ
    results_file = output_dir / "top3_evolution_analysis.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False, default=str)
    
    # ç”Ÿæˆæ‘˜è¦å ±å‘Š
    summary = generate_summary_report(all_results, output_dir)
    
    print(f"\nâœ… Top{top_n} æ¼”åŒ–åˆ†æå®Œæˆ!")
    print(f"   ğŸ“Š åˆ†æäº† {len(available_generations)} å€‹ä¸–ä»£")
    print(f"   ğŸ“ˆ ç¸½å…±åˆ†æäº† {len(all_results)} å€‹å€‹é«”")
    print(f"   ğŸ“„ è©³ç´°çµæœ: {results_file}")
    print(f"   ğŸ“‹ æ‘˜è¦å ±å‘Š: {output_dir / 'evolution_summary.json'}")
    if generate_plots:
        print(f"   ğŸ¨ ç¸¾æ•ˆåœ–è¡¨: {plots_dir}")
    
    return all_results


def generate_summary_report(all_results, output_dir):
    """ç”Ÿæˆæ‘˜è¦å ±å‘Š"""
    summary = {
        'analysis_time': datetime.now().isoformat(),
        'total_individuals': len(all_results),
        'generations_analyzed': len(set(r['generation'] for r in all_results)),
        'fitness_evolution': {},
        'best_performers': {}
    }
    
    # æŒ‰ä¸–ä»£åˆ†çµ„åˆ†æé©æ‡‰åº¦æ¼”åŒ–
    by_generation = {}
    for result in all_results:
        gen = result['generation']
        if gen not in by_generation:
            by_generation[gen] = []
        by_generation[gen].append(result)
    
    # é©æ‡‰åº¦æ¼”åŒ–è¶¨å‹¢
    for gen, results in by_generation.items():
        fitness_values = [r['fitness'] for r in results if r['fitness'] is not None]
        if fitness_values:
            summary['fitness_evolution'][f'generation_{gen}'] = {
                'best_fitness': max(fitness_values),
                'avg_fitness': sum(fitness_values) / len(fitness_values),
                'worst_fitness': min(fitness_values)
            }
    
    # æ‰¾å‡ºæœ€ä½³è¡¨ç¾è€…
    train_performers = [r for r in all_results 
                       if r.get('train_backtest') and 'fitness' in r['train_backtest']]
    test_performers = [r for r in all_results 
                      if r.get('test_backtest') and 'fitness' in r['test_backtest']]
    
    if train_performers:
        best_train = max(train_performers, 
                        key=lambda x: x['train_backtest']['fitness'])
        summary['best_performers']['training'] = {
            'individual_id': best_train['individual_id'],
            'generation': best_train['generation'],
            'rank': best_train['rank'],
            'fitness': best_train['train_backtest']['fitness']
        }
    
    if test_performers:
        best_test = max(test_performers, 
                       key=lambda x: x['test_backtest']['fitness'])
        summary['best_performers']['testing'] = {
            'individual_id': best_test['individual_id'],
            'generation': best_test['generation'],
            'rank': best_test['rank'],
            'fitness': best_test['test_backtest']['fitness']
        }
    
    # ä¿å­˜æ‘˜è¦
    summary_file = output_dir / "evolution_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    return summary


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description='åˆ†ææ¯ä¸–ä»£ Top3 å€‹é«”çš„æ¼”åŒ–éç¨‹å’Œå›æ¸¬ç¸¾æ•ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  python analyze_top3_evolution.py --records small_test_500x10_records --plots
  python analyze_top3_evolution.py --records small_test_500x10_records --no-plots --top-n 5
        """
    )
    
    parser.add_argument('--records', required=True,
                       help='æ¼”åŒ–è¨˜éŒ„ç›®éŒ„è·¯å¾‘')
    parser.add_argument('--config',
                       help='é…ç½®æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--plots', action='store_true', default=True,
                       help='ç”Ÿæˆç¸¾æ•ˆåœ–è¡¨ (é»˜èªé–‹å•Ÿ)')
    parser.add_argument('--no-plots', action='store_true',
                       help='ä¸ç”Ÿæˆç¸¾æ•ˆåœ–è¡¨')
    parser.add_argument('--top-n', type=int, default=3,
                       help='åˆ†æå‰Nåå€‹é«” (é»˜èª: 3)')
    
    args = parser.parse_args()
    
    # è¨­ç½® DEAP creator
    setup_deap_creator()
    
    print("ğŸ“Š" * 60)
    print("ğŸ“Š Top3 å€‹é«”æ¼”åŒ–åˆ†æ")
    print("ğŸ“Š" * 60)
    
    try:
        # è¼‰å…¥é…ç½®
        if args.config:
            config_path = Path(args.config)
        else:
            config_path = Path(args.records) / "config.json"
        
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        print(f"ğŸ“„ è¼‰å…¥é…ç½®: {config_path}")
        
        # è¼‰å…¥æ•¸æ“š
        print("ğŸ“Š è¼‰å…¥æ•¸æ“š...")
        from gp_quant.data.loader import split_train_test_data
        
        tickers_dir = Path(config['data']['tickers_dir'])
        if not tickers_dir.is_absolute():
            tickers_dir = Path.cwd() / tickers_dir
        
        tickers = [f.stem for f in tickers_dir.glob("*.csv")]
        raw_data = load_and_process_data(str(tickers_dir), tickers)
        
        train_data, test_data = split_train_test_data(
            raw_data,
            train_data_start=config['data']['train_data_start'],
            train_backtest_start=config['data']['train_backtest_start'],
            train_backtest_end=config['data']['train_backtest_end'],
            test_data_start=config['data']['test_data_start'],
            test_backtest_start=config['data']['test_backtest_start'],
            test_backtest_end=config['data']['test_backtest_end']
        )
        
        print(f"âœ… æ•¸æ“šè¼‰å…¥å®Œæˆ: è¨“ç·´({len(train_data)}), æ¸¬è©¦({len(test_data)})")
        
        # æ±ºå®šæ˜¯å¦ç”Ÿæˆåœ–è¡¨
        generate_plots = args.plots and not args.no_plots
        
        # åŸ·è¡Œåˆ†æ
        results = analyze_top3_evolution(
            args.records, config, train_data, test_data, 
            generate_plots=generate_plots, top_n=args.top_n)
        
        if results:
            print(f"\nğŸ‰ åˆ†ææˆåŠŸå®Œæˆ!")
            return 0
        else:
            print(f"\nâŒ åˆ†æå¤±æ•—!")
            return 1
            
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
