#!/usr/bin/env python3
"""
ç¹¼çºŒæ¼”åŒ–è…³æœ¬ - å¾ä¿å­˜çš„ç‹€æ…‹ç¹¼çºŒæ¼”åŒ–è¨ˆç®—
"""
import argparse
import json
from pathlib import Path
from datetime import datetime

from gp_quant.data.loader import load_and_process_data
from gp_quant.evolution.components.loader import EvolutionLoader, analyze_saved_evolution


def setup_deap_creator():
    """åˆå§‹åŒ– DEAP creator"""
    from deap import creator, base
    
    # æª¢æŸ¥æ˜¯å¦å·²ç¶“å‰µå»º
    if not hasattr(creator, 'FitnessMax'):
        creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    
    if not hasattr(creator, 'Individual'):
        from deap import gp
        creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessMax)


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description='å¾ä¿å­˜çš„ç‹€æ…‹ç¹¼çºŒæ¼”åŒ–è¨ˆç®—',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  python continue_evolution.py --records test_evolution_records --generations 10
  python continue_evolution.py --records test_evolution_records --analyze
        """
    )
    
    parser.add_argument('--records', required=True,
                       help='æ¼”åŒ–è¨˜éŒ„ç›®éŒ„è·¯å¾‘')
    parser.add_argument('--generations', type=int, default=10,
                       help='é¡å¤–çš„æ¼”åŒ–ä¸–ä»£æ•¸ (é»˜èª: 10)')
    parser.add_argument('--analyze', action='store_true',
                       help='åªåˆ†æä¿å­˜çš„æ¼”åŒ–æ•¸æ“šï¼Œä¸ç¹¼çºŒæ¼”åŒ–')
    parser.add_argument('--config', 
                       help='é…ç½®æ–‡ä»¶è·¯å¾‘ (ç”¨æ–¼è¼‰å…¥æ•¸æ“šé…ç½®)')
    
    args = parser.parse_args()
    
    # è¨­ç½® DEAP creator
    setup_deap_creator()
    
    print("ğŸ”„" * 60)
    print("ğŸ”„ æ¼”åŒ–ç‹€æ…‹é‡è¼‰èˆ‡ç¹¼çºŒ")
    print("ğŸ”„" * 60)
    
    try:
        # å‰µå»ºè¼‰å…¥å™¨
        loader = EvolutionLoader(args.records)
        
        if args.analyze:
            # åªåˆ†ææ•¸æ“š
            print("ğŸ“Š åˆ†æä¿å­˜çš„æ¼”åŒ–æ•¸æ“š...")
            analysis = analyze_saved_evolution(args.records)
            
            print("\nğŸ“ˆ æ¼”åŒ–é€²åº¦åˆ†æ:")
            print(f"   ğŸ“Š ç¸½ä¸–ä»£æ•¸: {analysis.get('total_generations', 0)}")
            print(f"   ğŸ”¢ ä¸–ä»£ç¯„åœ: {analysis.get('generation_range', 'N/A')}")
            print(f"   ğŸ“‹ çµ±è¨ˆæ•¸æ“š: {'âœ…' if analysis.get('has_statistics', False) else 'âŒ'}")
            
            if 'best_fitness_overall' in analysis:
                print(f"   ğŸ† æœ€ä½³é©æ‡‰åº¦: {analysis['best_fitness_overall']:.6f}")
                print(f"   ğŸ“‰ æœ€å·®é©æ‡‰åº¦: {analysis['worst_fitness_overall']:.6f}")
                print(f"   ğŸ“ˆ é©æ‡‰åº¦æ”¹é€²: {analysis['fitness_improvement']:.6f}")
                print(f"   ğŸ¯ æ”¶æ–‚æª¢æ¸¬: {'âœ…' if analysis.get('convergence_detected', False) else 'âŒ'}")
            
            print(f"\nğŸ“ å¯ç”¨ä¸–ä»£: {analysis.get('available_generations', [])}")
            
        else:
            # ç¹¼çºŒæ¼”åŒ–
            print(f"ğŸ“ è¨˜éŒ„ç›®éŒ„: {args.records}")
            print(f"â• é¡å¤–ä¸–ä»£: {args.generations}")
            
            # è¼‰å…¥é…ç½®å’Œæ•¸æ“š
            if args.config:
                config_path = Path(args.config)
            else:
                # å˜—è©¦å¾è¨˜éŒ„ç›®éŒ„è¼‰å…¥é…ç½®
                config_path = Path(args.records) / "config.json"
            
            if not config_path.exists():
                raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            print(f"ğŸ“„ è¼‰å…¥é…ç½®: {config_path}")
            
            # è¼‰å…¥æ•¸æ“š
            print("ğŸ“Š è¼‰å…¥æ•¸æ“š...")
            tickers_dir = Path(config['data']['tickers_dir'])
            if not tickers_dir.is_absolute():
                tickers_dir = Path.cwd() / tickers_dir
            
            data = load_and_process_data(
                str(tickers_dir),
                mode=config['data']['mode'],
                train_data_start=config['data']['train_data_start'],
                train_backtest_start=config['data']['train_backtest_start'],
                train_backtest_end=config['data']['train_backtest_end'],
                test_data_start=config['data']['test_data_start'],
                test_backtest_start=config['data']['test_backtest_start'],
                test_backtest_end=config['data']['test_backtest_end']
            )
            
            print(f"âœ… æ•¸æ“šè¼‰å…¥å®Œæˆ: {len(data)} å€‹è‚¡ç¥¨")
            
            # ç¹¼çºŒæ¼”åŒ–
            print(f"\nğŸš€ é–‹å§‹ç¹¼çºŒæ¼”åŒ–...")
            start_time = datetime.now()
            
            result = loader.continue_evolution(args.generations, data)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # è¼¸å‡ºçµæœ
            print(f"\nâœ… æ¼”åŒ–ç¹¼çºŒå®Œæˆ!")
            print(f"â±ï¸  åŸ·è¡Œæ™‚é–“: {duration:.2f} ç§’ ({duration/60:.2f} åˆ†é˜)")
            print(f"ğŸ“ˆ æœ€çµ‚ä¸–ä»£: {result.final_generation}")
            print(f"ğŸ† æœ€ä½³é©æ‡‰åº¦: {result.best_fitness:.4f}")
            
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
