"""
æ¡æ¨£ç›¸ä¼¼åº¦çŸ©é™£è¨ˆç®—

ä½¿ç”¨æ¡æ¨£ç­–ç•¥åŠ é€Ÿå¤§æ—ç¾¤çš„ç›¸ä¼¼åº¦çŸ©é™£è¨ˆç®—ï¼š
1. å®Œæ•´è¨ˆç®—ï¼šéš¨æ©Ÿæ¡æ¨£ N å€‹ä»£è¡¨æ€§å€‹é«”
2. è¿‘ä¼¼è¨ˆç®—ï¼šå…¶ä»–å€‹é«”åªèˆ‡ä»£è¡¨æ€§å€‹é«”è¨ˆç®—ç›¸ä¼¼åº¦
3. çŸ©é™£è£œå…¨ï¼šä½¿ç”¨æ’å€¼ä¼°ç®—æœªè¨ˆç®—çš„é…å°

é€™å¯ä»¥å°‡è¨ˆç®—é‡å¾ O(nÂ²) é™åˆ° O(n*k)ï¼Œå…¶ä¸­ k << n
"""

from typing import List, Tuple, Optional
import numpy as np
from multiprocessing import Pool
from functools import partial
from tqdm import tqdm

from .tree_edit_distance import (
    TreeEditDistance,
    TreeNode,
    deap_to_tree_node,
    DEAP_AVAILABLE
)

if DEAP_AVAILABLE:
    from deap import gp


def _compute_distance_batch(
    pairs: List[Tuple[int, int]],
    trees: List[TreeNode],
    cost_insert: Optional[callable] = None,
    cost_delete: Optional[callable] = None,
    cost_rename: Optional[callable] = None
) -> List[Tuple[int, int, float]]:
    """è¨ˆç®—ä¸€æ‰¹é…å°çš„è·é›¢ï¼ˆworker å‡½æ•¸ï¼‰"""
    ted = TreeEditDistance(
        cost_insert=cost_insert,
        cost_delete=cost_delete,
        cost_rename=cost_rename
    )
    
    results = []
    for i, j in pairs:
        distance = ted.compute(trees[i], trees[j])
        results.append((i, j, distance))
    
    return results


class SampledSimilarityMatrix:
    """
    æ¡æ¨£ç›¸ä¼¼åº¦çŸ©é™£è¨ˆç®—å™¨
    
    ä½¿ç”¨æ¡æ¨£ç­–ç•¥åŠ é€Ÿè¨ˆç®—ï¼š
    - é¸æ“‡ sample_size å€‹ä»£è¡¨æ€§å€‹é«”
    - æ‰€æœ‰å€‹é«”åªèˆ‡ä»£è¡¨æ€§å€‹é«”è¨ˆç®—ç›¸ä¼¼åº¦
    - ä½¿ç”¨ k-NN æ’å€¼ä¼°ç®—æœªè¨ˆç®—çš„é…å°
    """
    
    def __init__(self, 
                 population: List,
                 sample_size: int = 500,
                 n_workers: int = 8,
                 cost_insert: Optional[callable] = None,
                 cost_delete: Optional[callable] = None,
                 cost_rename: Optional[callable] = None):
        """
        åˆå§‹åŒ–æ¡æ¨£ç›¸ä¼¼åº¦çŸ©é™£è¨ˆç®—å™¨
        
        Args:
            population: DEAP æ—ç¾¤
            sample_size: æ¡æ¨£å€‹é«”æ•¸é‡ï¼ˆå»ºè­° 500-1000ï¼‰
            n_workers: ä¸¦è¡Œ worker æ•¸é‡
            cost_insert: æ’å…¥æˆæœ¬å‡½æ•¸
            cost_delete: åˆªé™¤æˆæœ¬å‡½æ•¸
            cost_rename: é‡å‘½åæˆæœ¬å‡½æ•¸
        """
        self.population = population
        self.n = len(population)
        self.sample_size = min(sample_size, self.n)
        self.n_workers = n_workers
        
        self.cost_insert = cost_insert
        self.cost_delete = cost_delete
        self.cost_rename = cost_rename
        
        self.matrix = None
        self.distance_matrix = None
        self.sample_indices = None
        
    def _convert_population(self) -> List[TreeNode]:
        """è½‰æ› DEAP population ç‚º TreeNode åˆ—è¡¨"""
        if not DEAP_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£ DEAP æ‰èƒ½ä½¿ç”¨æ­¤åŠŸèƒ½")
        
        trees = []
        for ind in self.population:
            tree_node = deap_to_tree_node(ind)
            trees.append(tree_node)
        return trees
    
    def _select_samples(self) -> np.ndarray:
        """
        é¸æ“‡ä»£è¡¨æ€§å€‹é«”
        
        ç­–ç•¥ï¼š
        1. æŒ‰ fitness æ’åºï¼Œé¸æ“‡ top 20%
        2. å¾å‰©é¤˜å€‹é«”ä¸­éš¨æ©Ÿé¸æ“‡
        3. ç¢ºä¿è¦†è“‹ä¸åŒ fitness ç¯„åœ
        
        Returns:
            np.ndarray: æ¡æ¨£å€‹é«”çš„ç´¢å¼•
        """
        # ç²å– fitness å€¼
        fitness_values = np.array([ind.fitness.values[0] for ind in self.population])
        
        # ç­–ç•¥ 1: é¸æ“‡ top 20%
        n_top = max(1, int(self.sample_size * 0.2))
        top_indices = np.argsort(fitness_values)[-n_top:]
        
        # ç­–ç•¥ 2: å¾å‰©é¤˜å€‹é«”ä¸­åˆ†å±¤æ¡æ¨£
        remaining_indices = np.setdiff1d(np.arange(self.n), top_indices)
        n_remaining = self.sample_size - n_top
        
        if n_remaining > 0:
            # åˆ†å±¤æ¡æ¨£ï¼šæŒ‰ fitness åˆ†æˆ 5 å±¤ï¼Œæ¯å±¤å‡å‹»æ¡æ¨£
            n_strata = 5
            strata_indices = []
            
            remaining_fitness = fitness_values[remaining_indices]
            percentiles = np.linspace(0, 100, n_strata + 1)
            
            for i in range(n_strata):
                lower = np.percentile(remaining_fitness, percentiles[i])
                upper = np.percentile(remaining_fitness, percentiles[i + 1])
                
                stratum_mask = (remaining_fitness >= lower) & (remaining_fitness <= upper)
                stratum_indices_local = np.where(stratum_mask)[0]
                
                if len(stratum_indices_local) > 0:
                    # å¾é€™ä¸€å±¤æ¡æ¨£
                    n_sample_stratum = max(1, n_remaining // n_strata)
                    n_sample_stratum = min(n_sample_stratum, len(stratum_indices_local))
                    
                    sampled = np.random.choice(
                        stratum_indices_local,
                        size=n_sample_stratum,
                        replace=False
                    )
                    strata_indices.extend(remaining_indices[sampled])
            
            # å¦‚æœæ¡æ¨£ä¸è¶³ï¼Œéš¨æ©Ÿè£œå……
            if len(strata_indices) < n_remaining:
                remaining_pool = np.setdiff1d(remaining_indices, strata_indices)
                n_extra = n_remaining - len(strata_indices)
                n_extra = min(n_extra, len(remaining_pool))
                
                if n_extra > 0:
                    extra = np.random.choice(remaining_pool, size=n_extra, replace=False)
                    strata_indices.extend(extra)
            
            # åˆä½µ
            sample_indices = np.concatenate([top_indices, strata_indices[:n_remaining]])
        else:
            sample_indices = top_indices
        
        return sample_indices
    
    def compute(self, show_progress=True) -> np.ndarray:
        """
        è¨ˆç®—æ¡æ¨£ç›¸ä¼¼åº¦çŸ©é™£
        
        Args:
            show_progress: æ˜¯å¦é¡¯ç¤ºé€²åº¦æ¢
            
        Returns:
            np.ndarray: ç›¸ä¼¼åº¦çŸ©é™£ (n x n)
        """
        # é¸æ“‡ä»£è¡¨æ€§å€‹é«”
        self.sample_indices = self._select_samples()
        
        if show_progress:
            print(f"ğŸ“Š æ¡æ¨£ç­–ç•¥ï¼šå¾ {self.n} å€‹å€‹é«”ä¸­é¸æ“‡ {len(self.sample_indices)} å€‹ä»£è¡¨")
            print(f"   è¨ˆç®—é‡ï¼š{self.n * len(self.sample_indices)} å°ï¼ˆvs å®Œæ•´ {self.n * (self.n-1) // 2} å°ï¼‰")
            print(f"   åŠ é€Ÿæ¯”ï¼š{(self.n * (self.n-1) // 2) / (self.n * len(self.sample_indices)):.1f}x")
        
        # åˆå§‹åŒ–çŸ©é™£
        self.distance_matrix = np.zeros((self.n, self.n))
        self.matrix = np.zeros((self.n, self.n))
        np.fill_diagonal(self.matrix, 1.0)
        
        # è½‰æ›ç‚º TreeNode
        trees = self._convert_population()
        
        # ç”Ÿæˆé…å°ï¼šæ‰€æœ‰å€‹é«” vs ä»£è¡¨æ€§å€‹é«”
        pairs = []
        for i in range(self.n):
            for j in self.sample_indices:
                if i != j and i < j:  # é¿å…é‡è¤‡è¨ˆç®—
                    pairs.append((i, j))
        
        total_pairs = len(pairs)
        
        if show_progress:
            print(f"   ä½¿ç”¨ {self.n_workers} å€‹ workers ä¸¦è¡Œè¨ˆç®—...")
        
        # åˆ†é…é…å°åˆ°å„ worker
        chunk_size = max(1, total_pairs // (self.n_workers * 4))
        pair_chunks = [pairs[i:i+chunk_size] for i in range(0, total_pairs, chunk_size)]
        
        # å‰µå»º worker å‡½æ•¸
        worker_func = partial(
            _compute_distance_batch,
            trees=trees,
            cost_insert=self.cost_insert,
            cost_delete=self.cost_delete,
            cost_rename=self.cost_rename
        )
        
        # ä¸¦è¡Œè¨ˆç®—
        if show_progress:
            pbar = tqdm(total=len(pair_chunks), desc="æ¡æ¨£è¨ˆç®—", unit="batch")
        
        with Pool(processes=self.n_workers) as pool:
            results_iter = pool.imap_unordered(worker_func, pair_chunks)
            
            for batch_results in results_iter:
                for i, j, distance in batch_results:
                    self.distance_matrix[i][j] = distance
                    self.distance_matrix[j][i] = distance
                    
                    similarity = 1.0 / (1.0 + distance)
                    self.matrix[i][j] = similarity
                    self.matrix[j][i] = similarity
                
                if show_progress:
                    pbar.update(1)
        
        if show_progress:
            pbar.close()
        
        # çŸ©é™£è£œå…¨ï¼šä½¿ç”¨ k-NN æ’å€¼ä¼°ç®—æœªè¨ˆç®—çš„é…å°
        if show_progress:
            print("   è£œå…¨çŸ©é™£ï¼ˆk-NN æ’å€¼ï¼‰...")
        
        self._complete_matrix()
        
        return self.matrix
    
    def _complete_matrix(self, k=5):
        """
        ä½¿ç”¨ k-NN æ’å€¼è£œå…¨çŸ©é™£
        
        å°æ–¼æœªç›´æ¥è¨ˆç®—çš„é…å° (i, j)ï¼š
        1. æ‰¾åˆ° i å’Œ j çš„ k å€‹æœ€è¿‘é„°ï¼ˆåœ¨ä»£è¡¨æ€§å€‹é«”ä¸­ï¼‰
        2. ä½¿ç”¨é€™äº›é„°å±…çš„ç›¸ä¼¼åº¦åŠ æ¬Šå¹³å‡ä¼°ç®— sim(i, j)
        """
        # å°æ–¼æ¯å€‹éä»£è¡¨æ€§å€‹é«”å°
        for i in range(self.n):
            if i in self.sample_indices:
                continue
            
            for j in range(i + 1, self.n):
                if j in self.sample_indices:
                    continue
                
                # å¦‚æœå·²ç¶“è¨ˆç®—éï¼Œè·³é
                if self.matrix[i][j] > 0:
                    continue
                
                # æ‰¾åˆ° i å’Œ j èˆ‡ä»£è¡¨æ€§å€‹é«”çš„ç›¸ä¼¼åº¦
                i_sims = self.matrix[i, self.sample_indices]
                j_sims = self.matrix[j, self.sample_indices]
                
                # ä½¿ç”¨ k å€‹æœ€ç›¸ä¼¼çš„ä»£è¡¨æ€§å€‹é«”
                k_actual = min(k, len(self.sample_indices))
                i_top_k = np.argsort(i_sims)[-k_actual:]
                j_top_k = np.argsort(j_sims)[-k_actual:]
                
                # è¨ˆç®—åŠ æ¬Šå¹³å‡
                # å¦‚æœ i å’Œ j èˆ‡ç›¸åŒçš„ä»£è¡¨æ€§å€‹é«”ç›¸ä¼¼ï¼Œå‰‡å®ƒå€‘å¯èƒ½ç›¸ä¼¼
                common_neighbors = np.intersect1d(i_top_k, j_top_k)
                
                if len(common_neighbors) > 0:
                    # ä½¿ç”¨å…±åŒé„°å±…çš„ç›¸ä¼¼åº¦
                    weights = i_sims[common_neighbors] * j_sims[common_neighbors]
                    estimated_sim = np.average(
                        i_sims[common_neighbors] * j_sims[common_neighbors],
                        weights=weights
                    )
                else:
                    # ä½¿ç”¨æ‰€æœ‰ top-k é„°å±…çš„å¹³å‡
                    all_neighbors = np.union1d(i_top_k, j_top_k)
                    estimated_sim = np.mean(i_sims[all_neighbors] * j_sims[all_neighbors])
                
                self.matrix[i][j] = estimated_sim
                self.matrix[j][i] = estimated_sim
    
    def get_similarity(self, i: int, j: int) -> float:
        """ç²å–å…©å€‹å€‹é«”ä¹‹é–“çš„ç›¸ä¼¼åº¦"""
        if self.matrix is None:
            raise ValueError("è«‹å…ˆèª¿ç”¨ compute() è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£")
        return self.matrix[i][j]
    
    def get_average_similarity(self) -> float:
        """è¨ˆç®—å¹³å‡ç›¸ä¼¼åº¦"""
        if self.matrix is None:
            raise ValueError("è«‹å…ˆèª¿ç”¨ compute() è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£")
        
        # æ’é™¤å°è§’ç·š
        n = self.matrix.shape[0]
        mask = ~np.eye(n, dtype=bool)
        return self.matrix[mask].mean()
    
    def get_diversity_score(self) -> float:
        """è¨ˆç®—æ—ç¾¤å¤šæ¨£æ€§åˆ†æ•¸ï¼ˆå¹³å‡ç›¸ç•°åº¦ï¼‰"""
        return 1.0 - self.get_average_similarity()
