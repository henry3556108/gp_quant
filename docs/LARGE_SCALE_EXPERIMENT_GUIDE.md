# ğŸš€ å¤§è¦æ¨¡æ¼”åŒ–å¯¦é©—æŒ‡å—

## ğŸ“‹ **å¯¦é©—é…ç½®**

### **åŸºæœ¬åƒæ•¸**
- **æ—ç¾¤å¤§å°**: 10,000 å€‹é«”
- **æ¼”åŒ–ä¸–ä»£**: 25 ä»£
- **ä¸¦è¡Œè™•ç†å™¨**: 6 æ ¸å¿ƒ
- **éš¨æ©Ÿç¨®å­**: 42ï¼ˆå¯é‡ç¾ï¼‰

### **æ¼”åŒ–ç­–ç•¥**
- **åˆå§‹åŒ–**: Ramped Half-and-Half (æ·±åº¦ 3-8)
- **é¸æ“‡**: Ranked SUS (éŒ¦æ¨™è³½å¤§å° 7ï¼Œç²¾è‹± 50)
- **äº¤é…**: One-Point Leaf-Biased (æ©Ÿç‡ 75%ï¼Œæœ€å¤§æ·±åº¦ 17)
- **è®Šç•°**: Uniform (æ©Ÿç‡ 5%ï¼Œæœ€å¤§æ·±åº¦ 17)
- **æ›¿æ›**: Elitist (ä¿ç•™å‰ 50 å)

### **é©æ‡‰åº¦å‡½æ•¸**
- **å‡½æ•¸**: Excess Returnï¼ˆè¶…é¡å ±é…¬ï¼‰
- **ä¸¦è¡Œè©•ä¼°**: 6 æ ¸å¿ƒ
- **ç·©å­˜**: å•Ÿç”¨

### **çµ‚æ­¢æ¢ä»¶**
- **æ—©åœ**: å•Ÿç”¨
- **è€å¿ƒå€¼**: 10 ä»£
- **æœ€å°æ”¹å–„**: 0.0001

---

## â±ï¸ **åŸ·è¡Œæ™‚é–“ä¼°ç®—**

### **åŸºæ–¼æ¸¬è©¦çµæœæ¨ç®—**

æ¸¬è©¦çµæœï¼ˆ100 å€‹é«” Ã— 10 ä»£ï¼‰ï¼š
- åˆå§‹è©•ä¼°: ~1 ç§’
- ç¸½æ™‚é–“: ~1.5 ç§’

å¤§è¦æ¨¡å¯¦é©—ï¼ˆ10000 å€‹é«” Ã— 25 ä»£ï¼‰ï¼š
- **åˆå§‹è©•ä¼°** (10000 å€‹é«”): ~150 ç§’ (2.5 åˆ†é˜)
- **æ¯ä¸–ä»£è©•ä¼°** (~7500 å€‹é«”): ~112 ç§’ (1.9 åˆ†é˜)
- **25 ä¸–ä»£ç¸½è¨ˆ**: ~2800 ç§’ (47 åˆ†é˜)
- **ä¿å­˜è¨Šè™Ÿæ™‚é–“**: ~800 ç§’ (13 åˆ†é˜)

**é è¨ˆç¸½æ™‚é–“**: ç´„ **60 åˆ†é˜**ï¼ˆ1 å°æ™‚ï¼‰

### **æ™‚é–“åˆ†é…**
```
åˆå§‹è©•ä¼°:     2.5 åˆ†é˜  (4%)
ä¸–ä»£ 1-25:   47.0 åˆ†é˜ (78%)
ä¿å­˜è¨Šè™Ÿ:    13.0 åˆ†é˜ (22%)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç¸½è¨ˆ:        60.0 åˆ†é˜
```

---

## ğŸ’¾ **é æœŸè³‡æºä½¿ç”¨**

### **ç£ç›¤ç©ºé–“**
- **æ—ç¾¤æ•¸æ“š**: ~500 MB (26 ä¸–ä»£ Ã— 10000 å€‹é«”)
- **è¨Šè™Ÿæ•¸æ“š**: ~200 MB (26 ä¸–ä»£ Ã— 4 è‚¡ç¥¨ Ã— è¨Šè™Ÿ)
- **çµ±è¨ˆæ•¸æ“š**: ~10 MB
- **ç¸½è¨ˆ**: ç´„ **700-800 MB**

### **å…§å­˜ä½¿ç”¨**
- **ä¸»é€²ç¨‹**: ~500 MB
- **6 å€‹å­é€²ç¨‹**: ~300 MB Ã— 6 = 1.8 GB
- **ç¸½è¨ˆ**: ç´„ **2.3 GB**

### **CPU ä½¿ç”¨**
- **ä¸¦è¡Œè©•ä¼°**: 6 æ ¸å¿ƒ 100% ä½¿ç”¨ç‡
- **å–®é€²ç¨‹æ“ä½œ**: 1 æ ¸å¿ƒä½¿ç”¨ç‡

---

## ğŸš€ **åŸ·è¡Œæ­¥é©Ÿ**

### **æ–¹æ³• 1: ä½¿ç”¨å•Ÿå‹•è…³æœ¬ï¼ˆæ¨è–¦ï¼‰**

```bash
python run_large_scale_experiment.py
```

è…³æœ¬æœƒï¼š
1. âœ… æª¢æŸ¥å‰ç½®æ¢ä»¶
2. â±ï¸  é¡¯ç¤ºæ™‚é–“ä¼°ç®—
3. â“ è¦æ±‚ç¢ºèª
4. ğŸš€ é‹è¡Œå¯¦é©—
5. ğŸ“Š é¡¯ç¤ºçµæœæ‘˜è¦

### **æ–¹æ³• 2: ç›´æ¥é‹è¡Œ**

```bash
python main_evolution.py --config configs/large_scale_experiment.json --verbose
```

### **æ–¹æ³• 3: èƒŒæ™¯é‹è¡Œï¼ˆé•·æ™‚é–“å¯¦é©—ï¼‰**

```bash
nohup python main_evolution.py --config configs/large_scale_experiment.json --verbose > experiment.log 2>&1 &

# æŸ¥çœ‹é€²åº¦
tail -f experiment.log

# æŸ¥çœ‹é€²ç¨‹
ps aux | grep main_evolution
```

---

## ğŸ“Š **ç”Ÿæˆçš„æ–‡ä»¶çµæ§‹**

```
large_scale_records_20251124_1730/
â”œâ”€â”€ config.json                          # å¯¦é©—é…ç½®
â”œâ”€â”€ generation_stats.json                # ä¸–ä»£çµ±è¨ˆ
â”œâ”€â”€ final_result.json                    # æœ€çµ‚çµæœ
â”œâ”€â”€ engine_state.pkl                     # æ¼”åŒ–å¼•æ“ç‹€æ…‹
â”œâ”€â”€ experiment_summary.json              # å¯¦é©—æ‘˜è¦
â”‚
â”œâ”€â”€ populations/                         # æ—ç¾¤æ•¸æ“š
â”‚   â”œâ”€â”€ generation_000.pkl               # å®Œæ•´å€‹é«”ï¼ˆå¯é‡è¼‰ï¼‰
â”‚   â”œâ”€â”€ generation_000_stats.json        # çµ±è¨ˆæ•¸æ“šï¼ˆå¯è®€ï¼‰
â”‚   â”œâ”€â”€ generation_001.pkl
â”‚   â”œâ”€â”€ generation_001_stats.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ genealogy/                           # è­œç³»æ•¸æ“š
â”‚   â”œâ”€â”€ generation_000.json
â”‚   â”œâ”€â”€ generation_001.json
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ best_signals/                        # æœ€ä½³å€‹é«”è¨Šè™Ÿ
    â”œâ”€â”€ generation_000/
    â”‚   â”œâ”€â”€ backtest_summary.json        # å›æ¸¬æ‘˜è¦
    â”‚   â”œâ”€â”€ entry_exit_points.csv        # äº¤æ˜“è¨˜éŒ„
    â”‚   â”œâ”€â”€ signals_ABX.TO.csv           # è¨Šè™Ÿ
    â”‚   â”œâ”€â”€ signals_BBD-B.TO.csv
    â”‚   â”œâ”€â”€ signals_RY.TO.csv
    â”‚   â””â”€â”€ signals_TRP.TO.csv
    â”œâ”€â”€ generation_001/
    â””â”€â”€ ...
    â””â”€â”€ generation_025/                  # æœ€çµ‚ä¸–ä»£
        â””â”€â”€ ...
```

---

## ğŸ“ˆ **ç›£æ§é€²åº¦**

### **å¯¦æ™‚ç›£æ§**

```bash
# æŸ¥çœ‹ç•¶å‰ä¸–ä»£
tail -f large_scale_records_*/generation_stats.json

# æŸ¥çœ‹æœ€ä½³é©æ‡‰åº¦
cat large_scale_records_*/generation_stats.json | jq '.[] | {generation, best_fitness}'

# æŸ¥çœ‹é€²ç¨‹ç‹€æ…‹
ps aux | grep main_evolution

# æŸ¥çœ‹ CPU ä½¿ç”¨ç‡
top -pid $(pgrep -f main_evolution)
```

### **é€²åº¦æŒ‡æ¨™**

æ¯å€‹ä¸–ä»£æœƒé¡¯ç¤ºï¼š
```
ğŸ”„ ç¬¬ 5/25 ä¸–ä»£
è©•ä¼°å€‹é«”: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7500/7500 [01:52<00:00, 66.67å€‹é«”/s]
ğŸ’¾ ä¿å­˜ç¬¬ 5 ä¸–ä»£æ•¸æ“š...
   ğŸ“Š æœ€ä½³å€‹é«”è¨Šè™Ÿå·²ä¿å­˜: generation_005
   ğŸ“Š æœ€ä½³é©æ‡‰åº¦: 0.2345
```

---

## ğŸ” **çµæœåˆ†æ**

### **1. æŸ¥çœ‹æœ€çµ‚çµæœ**

```bash
# æœ€çµ‚çµæœæ‘˜è¦
cat large_scale_records_*/final_result.json | python -m json.tool

# æœ€ä½³é©æ‡‰åº¦
cat large_scale_records_*/final_result.json | jq '.best_fitness'

# æ”¶æ–‚ä¸–ä»£
cat large_scale_records_*/final_result.json | jq '.convergence_generation'
```

### **2. åˆ†ææ¼”åŒ–è¶¨å‹¢**

```python
import json
import pandas as pd
import matplotlib.pyplot as plt

# è¼‰å…¥çµ±è¨ˆæ•¸æ“š
with open('large_scale_records_*/generation_stats.json') as f:
    stats = json.load(f)

df = pd.DataFrame(stats)

# ç¹ªè£½é©æ‡‰åº¦è¶¨å‹¢
plt.figure(figsize=(12, 6))
plt.plot(df['generation'], df['best_fitness'], label='Best', marker='o')
plt.plot(df['generation'], df['avg_fitness'], label='Average', marker='s')
plt.xlabel('Generation')
plt.ylabel('Fitness')
plt.title('Fitness Evolution (10000 individuals Ã— 25 generations)')
plt.legend()
plt.grid(True)
plt.savefig('fitness_evolution.png', dpi=300)
```

### **3. åˆ†ææœ€ä½³ç­–ç•¥**

```bash
# æŸ¥çœ‹æœ€ä½³å€‹é«”çš„å›æ¸¬æ‘˜è¦
cat large_scale_records_*/best_signals/generation_025/backtest_summary.json | python -m json.tool

# æŸ¥çœ‹äº¤æ˜“è¨˜éŒ„
cat large_scale_records_*/best_signals/generation_025/entry_exit_points.csv | head -20

# çµ±è¨ˆäº¤æ˜“æ¬¡æ•¸
cat large_scale_records_*/best_signals/generation_025/entry_exit_points.csv | wc -l
```

### **4. æ¯”è¼ƒä¸åŒä¸–ä»£**

```python
import json
from pathlib import Path

# æ¯”è¼ƒç¬¬ 0ã€10ã€20ã€25 ä»£çš„æœ€ä½³å€‹é«”
generations = [0, 10, 20, 25]

for gen in generations:
    summary_file = f'large_scale_records_*/best_signals/generation_{gen:03d}/backtest_summary.json'
    with open(summary_file) as f:
        data = json.load(f)
    
    print(f"\nGeneration {gen}:")
    print(f"  Fitness: {data['fitness']:.4f}")
    print(f"  Total Return: {data['metrics']['total_return']:.4f}")
    print(f"  Sharpe Ratio: {data['metrics']['sharpe_ratio']:.4f}")
    print(f"  Transactions: {data['total_transactions']}")
```

---

## âš ï¸ **æ³¨æ„äº‹é …**

### **1. ç³»çµ±è³‡æº**
- ç¢ºä¿æœ‰è¶³å¤ çš„ç£ç›¤ç©ºé–“ï¼ˆè‡³å°‘ 1 GBï¼‰
- ç¢ºä¿æœ‰è¶³å¤ çš„å…§å­˜ï¼ˆè‡³å°‘ 3 GB å¯ç”¨ï¼‰
- å»ºè­°é—œé–‰å…¶ä»–è€—è³‡æºçš„ç¨‹åº

### **2. åŸ·è¡Œæ™‚é–“**
- é è¨ˆéœ€è¦ç´„ 1 å°æ™‚
- ä¸è¦åœ¨å¯¦é©—é€²è¡Œä¸­é—œé–‰é›»è…¦
- å¯ä»¥ä½¿ç”¨ `nohup` åœ¨èƒŒæ™¯é‹è¡Œ

### **3. ä¸­æ–·è™•ç†**
- å¦‚æœéœ€è¦ä¸­æ–·ï¼Œä½¿ç”¨ `Ctrl+C`
- å·²å®Œæˆçš„ä¸–ä»£æ•¸æ“šæœƒè¢«ä¿å­˜
- å¯ä»¥ä½¿ç”¨ `EvolutionLoader` é‡æ–°è¼‰å…¥ä¸¦ç¹¼çºŒ

### **4. çµæœé©—è­‰**
- æª¢æŸ¥ `final_result.json` ç¢ºèªå¯¦é©—å®Œæˆ
- é©—è­‰ `best_signals/generation_025/` å­˜åœ¨
- ç¢ºèªäº¤æ˜“è¨˜éŒ„æœ‰è²·å…¥å’Œè³£å‡º

---

## ğŸ¯ **æˆåŠŸæ¨™æº–**

å¯¦é©—æˆåŠŸçš„æ¨™èªŒï¼š
- âœ… å®Œæˆ 25 ä¸–ä»£æ¼”åŒ–
- âœ… æ¯ä¸–ä»£ä¿å­˜æœ€ä½³å€‹é«”è¨Šè™Ÿ
- âœ… æœ€ä½³é©æ‡‰åº¦ > 0ï¼ˆæ­£å ±é…¬ï¼‰
- âœ… äº¤æ˜“è¨˜éŒ„åŒ…å«è²·å…¥å’Œè³£å‡º
- âœ… æ‰€æœ‰æ–‡ä»¶æ­£ç¢ºç”Ÿæˆ

---

## ğŸ“ **å¯¦é©—å¾Œåˆ†ææ¸…å–®**

- [ ] æŸ¥çœ‹æœ€çµ‚é©æ‡‰åº¦å’Œæ”¶æ–‚ä¸–ä»£
- [ ] åˆ†æé©æ‡‰åº¦æ¼”åŒ–è¶¨å‹¢
- [ ] æª¢æŸ¥æœ€ä½³ç­–ç•¥çš„äº¤æ˜“è¨˜éŒ„
- [ ] é©—è­‰è¨Šè™Ÿèˆ‡äº¤æ˜“çš„å°æ‡‰é—œä¿‚
- [ ] æ¯”è¼ƒä¸åŒä¸–ä»£çš„ç­–ç•¥ç‰¹å¾µ
- [ ] åˆ†ææ—ç¾¤å¤šæ¨£æ€§è®ŠåŒ–
- [ ] è©•ä¼°ç­–ç•¥çš„ç©©å®šæ€§
- [ ] æº–å‚™æ¸¬è©¦é›†é©—è­‰

---

## ğŸš€ **å¿«é€Ÿé–‹å§‹**

```bash
# 1. ç¢ºèªé…ç½®
cat configs/large_scale_experiment.json

# 2. é‹è¡Œå¯¦é©—
python run_large_scale_experiment.py

# 3. ç­‰å¾…å®Œæˆï¼ˆç´„ 1 å°æ™‚ï¼‰

# 4. æŸ¥çœ‹çµæœ
cat large_scale_records_*/final_result.json | python -m json.tool

# 5. åˆ†ææœ€ä½³ç­–ç•¥
cat large_scale_records_*/best_signals/generation_025/backtest_summary.json
```

**æº–å‚™å¥½äº†å—ï¼Ÿè®“æˆ‘å€‘é–‹å§‹é€™æ¬¡å¤§è¦æ¨¡å¯¦é©—ï¼** ğŸš€
