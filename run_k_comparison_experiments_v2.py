"""
K å€¼å°æ¯”å¯¦é©—æ‰¹æ¬¡é‹è¡Œè…³æœ¬

é‹è¡Œ 3 å€‹å¯¦é©—ï¼š
1. å›ºå®š k=3 (baseline)
2. å›ºå®š k=8
3. å‹•æ…‹é¸æ“‡ (calibration)
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime
from deap import creator, base, gp, tools
import random
import json
import os
import dill

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from gp_quant.backtesting.portfolio_engine import PortfolioBacktestingEngine
from gp_quant.gp.operators import pset
from gp_quant.evolution.early_stopping import EarlyStopping
from gp_quant.similarity import SimilarityMatrix, ParallelSimilarityMatrix
from gp_quant.niching import NichingClusterer, CrossNicheSelector, create_k_selector


def run_experiment(exp_config, exp_name):
    """é‹è¡Œå–®å€‹å¯¦é©—ï¼ˆè¤‡è£½è‡ª run_portfolio_experiment.py çš„ main å‡½æ•¸ï¼‰"""
    
    print("\n" + "="*100)
    print(f"ğŸš€ å¯¦é©—: {exp_name}")
    print("="*100)
    print()
    
    CONFIG = exp_config
    
    print("ğŸ“‹ å¯¦é©—é…ç½®:")
    print(f"  è‚¡ç¥¨çµ„åˆ: {', '.join(CONFIG['tickers'])}")
    print(f"  æ—ç¾¤å¤§å°: {CONFIG['population_size']}")
    print(f"  æ¼”åŒ–ä¸–ä»£: {CONFIG['generations']}")
    print(f"  Fitness æŒ‡æ¨™: {CONFIG['fitness_metric']}")
    
    if CONFIG['niching_enabled']:
        print(f"  Niching ç­–ç•¥: å•Ÿç”¨")
        if 'niching_k_selection' in CONFIG:
            print(f"    - K å€¼é¸æ“‡: {CONFIG['niching_k_selection']} æ¨¡å¼")
            if CONFIG['niching_k_selection'] == 'calibration':
                print(f"    - æ ¡æº–æœŸ: å‰ {CONFIG.get('niching_k_calibration_gens', 3)} ä»£")
            print(f"    - K ç¯„åœ: [{CONFIG.get('niching_k_min', 2)}, {CONFIG.get('niching_k_max', 'auto')}]")
        else:
            print(f"    - Niche æ•¸é‡: {CONFIG['niching_n_clusters']} (å›ºå®š)")
        print(f"    - è·¨ç¾¤æ¯”ä¾‹: {CONFIG['niching_cross_ratio']:.0%}")
        print(f"    - æ›´æ–°é »ç‡: æ¯ {CONFIG['niching_update_frequency']} ä»£")
    print()
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    exp_dir = Path(CONFIG['output_dir']) / CONFIG['experiment_name']
    exp_dir.mkdir(parents=True, exist_ok=True)
    
    generations_dir = exp_dir / "generations"
    generations_dir.mkdir(exist_ok=True)
    
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {exp_dir}")
    print()
    
    # å„²å­˜é…ç½®
    with open(exp_dir / "config.json", 'w') as f:
        json.dump(CONFIG, f, indent=2)
    
    # è¼‰å…¥æ•¸æ“š
    print("1ï¸âƒ£  è¼‰å…¥å¸‚å ´æ•¸æ“š...")
    data = {}
    
    for ticker in CONFIG['tickers']:
        file_path = project_root / f"TSE300_selected/{ticker}.csv"
        if file_path.exists():
            df = pd.read_csv(file_path, index_col=0, parse_dates=True)
            data[ticker] = df
            print(f"   âœ“ {ticker}: {len(df)} å¤©")
        else:
            print(f"   âœ— {ticker}: æ–‡ä»¶ä¸å­˜åœ¨")
            return None
    
    print()
    
    # åˆå§‹åŒ– Engine
    print("2ï¸âƒ£  åˆå§‹åŒ– Backtesting Engine...")
    
    try:
        train_engine = PortfolioBacktestingEngine(
            data=data,
            backtest_start=CONFIG['train_backtest_start'],
            backtest_end=CONFIG['train_backtest_end'],
            initial_capital=CONFIG['initial_capital'],
            pset=pset
        )
        print(f"   âœ“ äº¤æ˜“æ—¥æ•¸: {len(train_engine.common_dates)}")
    except Exception as e:
        print(f"   âœ— åˆå§‹åŒ–å¤±æ•—: {e}")
        return None
    
    print()
    
    # è¨­ç½® DEAP
    print("3ï¸âƒ£  è¨­ç½® DEAP...")
    
    if not hasattr(creator, "FitnessMax"):
        creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    if not hasattr(creator, "Individual"):
        creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessMax)
    
    toolbox = base.Toolbox()
    toolbox.register("expr", gp.genHalfAndHalf, pset=pset, min_=1, max_=3)
    toolbox.register("individual", tools.initIterate, creator.Individual, toolbox.expr)
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)
    toolbox.register("compile", gp.compile, pset=pset)
    toolbox.register("select", tools.selTournament, tournsize=CONFIG['tournament_size'])
    toolbox.register("mate", gp.cxOnePoint)
    toolbox.register("mutate", gp.mutUniform, expr=toolbox.expr, pset=pset)
    
    def evaluate_individual(individual):
        try:
            fitness = train_engine.get_fitness(individual, fitness_metric=CONFIG['fitness_metric'])
            return (fitness,)
        except:
            return (-1000000.0,)
    
    toolbox.register("evaluate", evaluate_individual)
    
    print("   âœ“ DEAP è¨­ç½®å®Œæˆ")
    print()
    
    # å‰µå»ºçµ±è¨ˆå’Œ Hall of Fame
    stats = tools.Statistics(lambda ind: ind.fitness.values)
    stats.register("avg", np.mean)
    stats.register("std", np.std)
    stats.register("min", np.min)
    stats.register("max", np.max)
    
    hof = tools.HallOfFame(10)
    
    # å‰µå»ºåˆå§‹æ—ç¾¤
    print("4ï¸âƒ£  å‰µå»ºåˆå§‹æ—ç¾¤...")
    population = toolbox.population(n=CONFIG['population_size'])
    print(f"   âœ“ å‰µå»º {len(population)} å€‹å€‹é«”")
    print()
    
    # é–‹å§‹æ¼”åŒ–
    print("5ï¸âƒ£  é–‹å§‹ GP æ¼”åŒ–...")
    print("="*100)
    
    evolution_log = []
    niching_log = []
    start_time = datetime.now()
    
    # åˆå§‹åŒ– Niching æ©Ÿåˆ¶
    niching_selector = None
    k_selector = None
    niche_labels = None
    
    if CONFIG['niching_enabled']:
        niching_selector = CrossNicheSelector(
            cross_niche_ratio=CONFIG['niching_cross_ratio'],
            tournament_size=CONFIG['tournament_size'],
            random_state=42
        )
        
        # å‰µå»º k å€¼é¸æ“‡å™¨
        k_selector = create_k_selector(CONFIG)
        
        print(f"âœ“ Niching ç­–ç•¥å·²å•Ÿç”¨")
        if 'niching_k_selection' in CONFIG:
            print(f"  - K å€¼é¸æ“‡: {CONFIG['niching_k_selection']} æ¨¡å¼")
        else:
            print(f"  - Niche æ•¸é‡: {CONFIG['niching_n_clusters']} (å›ºå®š)")
        print()
    
    for gen in range(CONFIG['generations']):
        gen_start_time = datetime.now()
        
        print(f"\n{'='*100}")
        print(f"ğŸ“Š Generation {gen + 1}/{CONFIG['generations']}")
        print(f"{'='*100}")
        
        # è©•ä¼°æ—ç¾¤
        print(f"â³ è©•ä¼° {len(population)} å€‹å€‹é«”...")
        eval_start = datetime.now()
        
        invalid_ind = [ind for ind in population if not ind.fitness.valid]
        fitnesses = map(toolbox.evaluate, invalid_ind)
        for ind, fit in zip(invalid_ind, fitnesses):
            ind.fitness.values = fit
        
        eval_time = (datetime.now() - eval_start).total_seconds()
        print(f"âœ“ è©•ä¼°å®Œæˆ ({eval_time:.1f}s)")
        
        # æ›´æ–°çµ±è¨ˆ
        hof.update(population)
        record = stats.compile(population)
        
        # é¡¯ç¤ºçµ±è¨ˆ
        print(f"\nğŸ“ˆ Fitness çµ±è¨ˆ:")
        print(f"   Avg: {record['avg']:.4f} | Max: {record['max']:.4f} | Std: {record['std']:.4f}")
        
        # è¨˜éŒ„åˆ°æ—¥èªŒ
        gen_log = {
            'generation': gen + 1,
            'min_fitness': float(record['min']),
            'avg_fitness': float(record['avg']),
            'max_fitness': float(record['max']),
            'std_fitness': float(record['std']),
            'eval_time': eval_time,
        }
        evolution_log.append(gen_log)
        
        # å„²å­˜ç•¶å‰ä¸–ä»£
        print(f"\nğŸ’¾ å„²å­˜ Generation {gen + 1} æ—ç¾¤...")
        gen_file = generations_dir / f"generation_{gen+1:03d}.pkl"
        
        try:
            with open(gen_file, 'wb') as f:
                dill.dump({
                    'generation': gen + 1,
                    'population': population,
                    'hall_of_fame': list(hof),
                    'statistics': record,
                }, f)
            
            file_size = gen_file.stat().st_size / (1024 * 1024)
            print(f"   âœ“ å·²å„²å­˜: {gen_file.name} ({file_size:.2f} MB)")
        except Exception as e:
            print(f"   âœ— å„²å­˜å¤±æ•—: {e}")
        
        # é¸æ“‡å’Œç¹æ®–
        if gen < CONFIG['generations'] - 1:
            print(f"\nğŸ”„ é¸æ“‡å’Œç¹æ®–...")
            
            # Niching: è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£ä¸¦èšé¡
            if CONFIG['niching_enabled'] and gen % CONFIG['niching_update_frequency'] == 0:
                print(f"\nğŸ”¬ Niching: è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£...")
                sim_start = datetime.now()
                
                try:
                    if len(population) >= 200:
                        sim_matrix = ParallelSimilarityMatrix(population, n_workers=8)
                        similarity_matrix = sim_matrix.compute(show_progress=False)
                    else:
                        sim_matrix = SimilarityMatrix(population)
                        similarity_matrix = sim_matrix.compute(show_progress=False)
                    
                    sim_time = (datetime.now() - sim_start).total_seconds()
                    
                    print(f"   âœ“ ç›¸ä¼¼åº¦çŸ©é™£è¨ˆç®—å®Œæˆ ({sim_time:.1f}s)")
                    print(f"   å¹³å‡ç›¸ä¼¼åº¦: {sim_matrix.get_average_similarity():.4f}")
                    
                    # å‹•æ…‹é¸æ“‡ k å€¼
                    if k_selector is not None:
                        print(f"\nğŸ¯ é¸æ“‡ K å€¼...")
                        k_result = k_selector.select_k(
                            similarity_matrix,
                            population_size=len(population),
                            generation=gen + 1
                        )
                        selected_k = k_result['k']
                        print(f"   âœ“ é¸æ“‡çš„ K: {selected_k}")
                        if k_result.get('scores'):
                            best_score = k_result['scores'][selected_k]
                            print(f"   Silhouette Score: {best_score:.4f}")
                    else:
                        selected_k = CONFIG['niching_n_clusters']
                    
                    # èšé¡
                    print(f"\nğŸ”¬ Niching: èšé¡ï¼ˆk={selected_k}ï¼‰...")
                    clusterer = NichingClusterer(
                        n_clusters=selected_k,
                        algorithm=CONFIG['niching_algorithm']
                    )
                    niche_labels = clusterer.fit_predict(similarity_matrix)
                    
                    print(f"   âœ“ èšé¡å®Œæˆ")
                    print(f"   Silhouette åˆ†æ•¸: {clusterer.silhouette_score_:.4f}")
                    
                    # çµ±è¨ˆå„ niche å¤§å°
                    unique_niches, counts = np.unique(niche_labels, return_counts=True)
                    print(f"   å„ Niche å¤§å°: {dict(zip(unique_niches, counts))}")
                    
                    # é¡¯ç¤ºæ¯å€‹ niche çš„ silhouette score
                    if clusterer.per_cluster_silhouette_:
                        print(f"\n   å„ Niche Silhouette Score:")
                        for niche_id, niche_stats in clusterer.per_cluster_silhouette_.items():
                            print(f"     Niche {niche_id}: {niche_stats['mean']:.4f} (size={niche_stats['size']}, std={niche_stats['std']:.4f})")
                    
                    # è¨˜éŒ„ niching çµ±è¨ˆ
                    niching_stats = {
                        'generation': gen + 1,
                        'selected_k': int(selected_k),
                        'avg_similarity': float(sim_matrix.get_average_similarity()),
                        'diversity_score': float(sim_matrix.get_diversity_score()),
                        'silhouette_score': float(clusterer.silhouette_score_),
                        'niche_sizes': {int(k): int(v) for k, v in zip(unique_niches, counts)},
                        'per_niche_silhouette': clusterer.per_cluster_silhouette_,  # æ–°å¢ï¼šæ¯å€‹ niche çš„è©³ç´°ä¿¡æ¯
                        'computation_time': sim_time
                    }
                    if k_selector is not None and k_result.get('mode'):
                        niching_stats['k_selection_mode'] = k_result['mode']
                    niching_log.append(niching_stats)
                    
                except Exception as e:
                    print(f"   âœ— Niching è¨ˆç®—å¤±æ•—: {e}")
                    niche_labels = None
            
            # Selection
            if CONFIG['niching_enabled'] and niche_labels is not None:
                offspring = niching_selector.select(population, niche_labels, len(population))
                offspring = list(map(toolbox.clone, offspring))
            else:
                offspring = toolbox.select(population, len(population))
                offspring = list(map(toolbox.clone, offspring))
            
            # Crossover
            for child1, child2 in zip(offspring[::2], offspring[1::2]):
                if random.random() < CONFIG['crossover_prob']:
                    toolbox.mate(child1, child2)
                    del child1.fitness.values
                    del child2.fitness.values
            
            # Mutation
            for mutant in offspring:
                if random.random() < CONFIG['mutation_prob']:
                    toolbox.mutate(mutant)
                    del mutant.fitness.values
            
            population[:] = offspring
        
        gen_time = (datetime.now() - gen_start_time).total_seconds()
        print(f"\nâ±ï¸  Generation {gen + 1} è€—æ™‚: {gen_time:.1f}s")
    
    # æ¼”åŒ–å®Œæˆ
    total_time = (datetime.now() - start_time).total_seconds()
    
    print()
    print("="*100)
    print("âœ… æ¼”åŒ–å®Œæˆï¼")
    print("="*100)
    print(f"â±ï¸  ç¸½è€—æ™‚: {total_time/60:.2f} åˆ†é˜")
    print(f"ğŸ† æœ€ä½³ Fitness: {hof[0].fitness.values[0]:.4f}")
    print()
    
    # å„²å­˜çµæœ
    result = {
        'experiment_name': exp_name,
        'config': CONFIG,
        'evolution_log': evolution_log,
        'niching_log': niching_log,
        'total_time': total_time,
        'best_fitness': float(hof[0].fitness.values[0]),
    }
    
    # å„²å­˜ JSON
    with open(exp_dir / "result.json", 'w') as f:
        json.dump(result, f, indent=2)
    
    # å„²å­˜ CSV
    log_df = pd.DataFrame(evolution_log)
    log_df.to_csv(exp_dir / "evolution_log.csv", index=False)
    
    if niching_log:
        niching_df = pd.DataFrame(niching_log)
        niching_df.to_csv(exp_dir / "niching_log.csv", index=False)
    
    print(f"ğŸ’¾ çµæœå·²å„²å­˜è‡³: {exp_dir}")
    
    return result


def main():
    print("\n" + "="*100)
    print("ğŸ”¬ K å€¼å°æ¯”å¯¦é©—æ‰¹æ¬¡é‹è¡Œ")
    print("="*100)
    print()
    
    # åŸºç¤é…ç½®
    BASE_CONFIG = {
        'tickers': ['ABX.TO', 'BBD-B.TO', 'RY.TO', 'TRP.TO'],
        'train_data_start': '1995-01-03',
        'train_backtest_start': '1997-06-25',
        'train_backtest_end': '1999-06-25',
        'initial_capital': 100000.0,
        'population_size': 1000,
        'generations': 20,
        'crossover_prob': 0.8,
        'mutation_prob': 0.2,
        'tournament_size': 3,
        'fitness_metric': 'sharpe_ratio',
        'niching_enabled': True,
        'niching_cross_ratio': 0.8,
        'niching_update_frequency': 1,  # æ¯ä»£éƒ½æ›´æ–°
        'niching_algorithm': 'kmeans',
        'output_dir': 'k_comparison_experiments',
    }
    
    # å¯¦é©—é…ç½®
    experiments = [
        # å¯¦é©— 1: å›ºå®š k=3 (baseline)
        {
            **BASE_CONFIG,
            'experiment_name': 'exp_1_fixed_k3',
            'niching_n_clusters': 3,
        },
        
        # å¯¦é©— 2: å›ºå®š k=8
        {
            **BASE_CONFIG,
            'experiment_name': 'exp_2_fixed_k8',
            'niching_n_clusters': 8,
        },
        
        # å¯¦é©— 3: å‹•æ…‹é¸æ“‡ (calibration)
        {
            **BASE_CONFIG,
            'experiment_name': 'exp_3_dynamic_calibration',
            'niching_k_selection': 'calibration',
            'niching_k_min': 2,
            'niching_k_max': 'auto',
            'niching_k_calibration_gens': 3,
        },
    ]
    
    # é‹è¡Œæ‰€æœ‰å¯¦é©—
    results = []
    
    for i, exp_config in enumerate(experiments, 1):
        exp_name = exp_config['experiment_name']
        print(f"\n{'='*100}")
        print(f"ğŸš€ é–‹å§‹å¯¦é©— {i}/3: {exp_name}")
        print(f"{'='*100}")
        
        result = run_experiment(exp_config, exp_name)
        if result:
            results.append(result)
    
    # æ¯”è¼ƒçµæœ
    print("\n" + "="*100)
    print("ğŸ“Š å¯¦é©—çµæœæ¯”è¼ƒ")
    print("="*100)
    print()
    
    comparison_data = []
    for result in results:
        comparison_data.append({
            'å¯¦é©—': result['experiment_name'],
            'æœ€ä½³ Fitness': result['best_fitness'],
            'ç¸½æ™‚é–“ (åˆ†é˜)': result['total_time'] / 60,
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    print(comparison_df.to_string(index=False))
    print()
    
    # å„²å­˜æ¯”è¼ƒçµæœ
    comparison_df.to_csv('k_comparison_experiments/comparison_summary.csv', index=False)
    
    print("="*100)
    print("âœ… æ‰€æœ‰å¯¦é©—å®Œæˆï¼")
    print(f"ğŸ“ çµæœä¿å­˜åœ¨: k_comparison_experiments/")
    print("="*100)


if __name__ == "__main__":
    main()
